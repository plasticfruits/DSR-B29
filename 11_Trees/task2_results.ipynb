{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees: Ensemble Methods - Boosting\n",
    "\n",
    "Boosting is another ensemble technique to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analyzing data for errors. In other words, we fit consecutive trees (random sample) at every step,and the goal is to solve for net error from the prior tree.\n",
    "\n",
    "When an input is misclassified by a hypothesis, its weight is increased so that next hypothesis is more likely to classify it correctly. By combining the whole set at the end converts weak learners into a better performing model.\n",
    "\n",
    "An ensemble of trees are built one by one and individual trees are summed sequentially. The Next tree tries to recover the loss (difference between actual and predicted values) from the previous tree.\n",
    "\n",
    " - boosting = low variance, high bias base learners\n",
    " \n",
    " ![Boosting Example](./images/boosting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost = Adaptive Boosting\n",
    "AdaBoost learns from the mistakes by increasing the weight of misclassified data points.\n",
    "\n",
    "It is called Adaptive Boosting as the weights are re-assigned to each instance, with higher weights to incorrectly classified instances.\n",
    "\n",
    "*Adaboost usually has just a node and two leaves.(A tree with one node and two leaves is called a stump)*\n",
    "\n",
    "Steps:\n",
    "<li> 0: Initialize the weights of data points. (e.g. data has 1000 points, each initial point would have 1/1000 = 0.001) </li>\n",
    "<li> 1: Train a decision Tree (whole dataset) </li>\n",
    "<li> 2: Calculate the weighted error rate (e) of the decision tree. </li>\n",
    "<li> 3: Calculate this decision tree’s weight in the ensemble. The weight of this tree = learning rate * log( (1 — e) / e) </li> \n",
    "<br> ** The higher the weighted error of the tree, the less decision power the tree will be given during the later voting. </br>\n",
    "<br> ** The lower the weighted error of the tree, the higher decision power the tree will be given during the later voting. </br>\n",
    "\n",
    "<li> 4: Update weights of wrongly classified points. </li> \n",
    "<br> the weight of each data point stays same if the model got this data points correct.</br>\n",
    "<br> the <strong><em>new weight of this data point = old weight*exp(weight of the tree)</em></strong>, if the model got this data point wrong </br> \n",
    "\n",
    "<li> 5: Repeat step 1 (dataset with new weights) </li>\n",
    "<li> 6: Make final prediction </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further reading:https://www.mygreatlearning.com/blog/adaboost-algorithm/\n",
    "<br> https://www.analyticsvidhya.com/blog/2021/09/adaboost-algorithm-a-complete-guide-for-beginners/#:~:text=AdaBoost%20also%20called%20Adaptive%20Boosting,are%20also%20called%20Decision%20Stumps </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting = Gradient Descent + Boosting.\n",
    "Gradient Descent is a first-order iterative optimization algorithm for finding a local minimum of a differential function. If x(n+1) = x(n) - learning_rate*dF/dx(n) for a small learning_rate, then F(x(n)) => F(x(n+1)). (the idea is to move against the gradient).\n",
    "\n",
    "Just like AdaBoost, Gradient Boosting works by sequentially adding predictors to an ensemble, each one correcting its predecessor. However, instead of changing the weights for every incorrect classified observation at every iteration like AdaBoost, Gradient Boosting method tries to fit the new predictor to the residual errors made by the previous predictor.\n",
    "\n",
    "![Boosting_1](./images/gb_boost_1.png)\n",
    "\n",
    "![Boosting_2](./images/gb_boost_2.png)\n",
    "\n",
    "Steps:\n",
    "<li> 1: Calculate the average of the target label</li> \n",
    "<li> 2: Calculate the residuals </li> \n",
    "<li> 3: Construct a decision tree </li> \n",
    "<li> 4: Predict the target label using all of the trees within the ensemble </li> \n",
    "**Predicted Value = Average Value + Learning Rate*Residual Predicted by Decision Tree\n",
    "<li> 5: Compute the new residuals </li> \n",
    "<li>6: Repeat steps 3 to 5 until the number of iterations matches the number specified by the hyperparameter (i.e. number of estimators) </li>\n",
    "\n",
    "<strong>Note:</strong>\n",
    "\n",
    "<li> Gradient Boosting is prone to Over-fitting.</li>\n",
    "<li> Requires careful tuning of different hyper-parameters.</li>\n",
    "\n",
    "Example: https://towardsdatascience.com/machine-learning-part-18-boosting-algorithms-gradient-boosting-in-python-ef5ae6965be4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import catboost as cb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:55:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "--- 0.05968928337097168 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.583590106471756"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset\n",
    "\n",
    "X,y = load_boston(return_X_y=True)\n",
    "\n",
    "#train,test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#xgboost\n",
    "xgbr = xgb.XGBRegressor(max_depth=5,learning_rate=0.1,n_estimators=100,n_jobs=1)\n",
    "start_time = time.time()  #track the model development time\n",
    "\n",
    "xgbr.fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "y_predict = xgbr.predict(X_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time)) \n",
    "\n",
    "mean_squared_error(y_test,y_predict) #error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgboost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r2/npg0bdw94_x2md_1zwp1191h0000gn/T/ipykernel_2894/1361900062.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgboost' is not defined"
     ]
    }
   ],
   "source": [
    "xgboost\n",
    "lightgbm\n",
    "catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.09108877182006836 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.069578290965865"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try lightgbm\n",
    "#it splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise.\n",
    "\n",
    "lgbr = lgb.LGBMRegressor(learning_rate=0.1,n_estimators=100,max_depth=5,num_leaves=50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "lgbr.fit(X_train,y_train,verbose=0)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "y_predict = lgbr.predict(X_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "mean_squared_error(y_test,y_predict)    #error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.19351601600646973 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.344821856482579"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#catboost helps you savetime by preprocessing of categorical columns for you.\n",
    "#weighted sampling version of Stochastic Gradient Boosting.\n",
    "\n",
    "#lets try catboost\n",
    "cbr = cb.CatBoostRegressor(learning_rate=0.1,n_estimators=100,max_depth=5)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cbr.fit(X_train,y_train,verbose=0)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "y_predict = cbr.predict(X_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))\n",
    "\n",
    "mean_squared_error(y_test,y_predict)    #error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Load the promotion dataset from the data folder, train a model on the dataset and compare results using both random forests and gradient boosting.\n",
    "\n",
    "<strong>Note: Also make sure to do some data cleaning, upsampling/downsampling, parameter tuning.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_estimators`\n",
    "- increasing num trees will increase model complexity\n",
    "\n",
    "`max_features`\n",
    "- how many features to split on\n",
    "- rule of thumb = sqrt(num_features)\n",
    "- depends on ratio of noisy to important var in dataset\n",
    "- small num features = reduce variance increase bias\n",
    "- lots of noisy = small m will decrease probability of choosing an important variable at a split\n",
    "\n",
    "`min samples per leaf` \n",
    "- increase a bit (default is 1) to get smaller trees w less overfitting\n",
    "\n",
    "`max_depth`\n",
    "- controls variance\n",
    "\n",
    "`subsample`\n",
    "- The fraction of observations to be selected for each tree. Selection is done by random sampling.\n",
    "- Values slightly less than 1 make the model robust by reducing the variance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting point hyperparameters\n",
    "\n",
    "*** Heard from a Kaggle Grandmaster\n",
    "\n",
    "Learning rate = 0.05, 1000 rounds, max depth = 3-5, subsample = 0.8-1.0, colsample_bytree = 0.3 - 0.8, lambda = 0 to 5\n",
    "\n",
    "Add capacity to combat bias - add rounds\n",
    "\n",
    "Reduce capacity to combat variance - depth / regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeNo</th>\n",
       "      <th>Division</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Channel_of_Recruitment</th>\n",
       "      <th>Trainings_Attended</th>\n",
       "      <th>Year_of_birth</th>\n",
       "      <th>Last_performance_score</th>\n",
       "      <th>Year_of_recruitment</th>\n",
       "      <th>Targets_met</th>\n",
       "      <th>Previous_Award</th>\n",
       "      <th>Training_score_average</th>\n",
       "      <th>State_Of_Origin</th>\n",
       "      <th>Foreign_schooled</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Past_Disciplinary_Action</th>\n",
       "      <th>Previous_IntraDepartmental_Movement</th>\n",
       "      <th>No_of_previous_employers</th>\n",
       "      <th>Promoted_or_Not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YAK/S/00001</td>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>MSc, MBA and PhD</td>\n",
       "      <td>Female</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>2</td>\n",
       "      <td>1986</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>ANAMBRA</td>\n",
       "      <td>No</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YAK/S/00002</td>\n",
       "      <td>Customer Support and Field Operations</td>\n",
       "      <td>First Degree or HND</td>\n",
       "      <td>Male</td>\n",
       "      <td>Agency and others</td>\n",
       "      <td>2</td>\n",
       "      <td>1991</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>ANAMBRA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YAK/S/00003</td>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>First Degree or HND</td>\n",
       "      <td>Male</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>KATSINA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YAK/S/00004</td>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>First Degree or HND</td>\n",
       "      <td>Male</td>\n",
       "      <td>Agency and others</td>\n",
       "      <td>3</td>\n",
       "      <td>1982</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>NIGER</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Single</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YAK/S/00006</td>\n",
       "      <td>Information and Strategy</td>\n",
       "      <td>First Degree or HND</td>\n",
       "      <td>Male</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>3</td>\n",
       "      <td>1990</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>AKWA IBOM</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EmployeeNo                               Division        Qualification  \\\n",
       "0  YAK/S/00001         Commercial Sales and Marketing     MSc, MBA and PhD   \n",
       "1  YAK/S/00002  Customer Support and Field Operations  First Degree or HND   \n",
       "2  YAK/S/00003         Commercial Sales and Marketing  First Degree or HND   \n",
       "3  YAK/S/00004         Commercial Sales and Marketing  First Degree or HND   \n",
       "4  YAK/S/00006               Information and Strategy  First Degree or HND   \n",
       "\n",
       "   Gender   Channel_of_Recruitment  Trainings_Attended  Year_of_birth  \\\n",
       "0  Female  Direct Internal process                   2           1986   \n",
       "1    Male        Agency and others                   2           1991   \n",
       "2    Male  Direct Internal process                   2           1987   \n",
       "3    Male        Agency and others                   3           1982   \n",
       "4    Male  Direct Internal process                   3           1990   \n",
       "\n",
       "   Last_performance_score  Year_of_recruitment  Targets_met  Previous_Award  \\\n",
       "0                    12.5                 2011            1               0   \n",
       "1                    12.5                 2015            0               0   \n",
       "2                     7.5                 2012            0               0   \n",
       "3                     2.5                 2009            0               0   \n",
       "4                     7.5                 2012            0               0   \n",
       "\n",
       "   Training_score_average State_Of_Origin Foreign_schooled Marital_Status  \\\n",
       "0                      41         ANAMBRA               No        Married   \n",
       "1                      52         ANAMBRA              Yes        Married   \n",
       "2                      42         KATSINA              Yes        Married   \n",
       "3                      42           NIGER              Yes         Single   \n",
       "4                      77       AKWA IBOM              Yes        Married   \n",
       "\n",
       "  Past_Disciplinary_Action Previous_IntraDepartmental_Movement  \\\n",
       "0                       No                                  No   \n",
       "1                       No                                  No   \n",
       "2                       No                                  No   \n",
       "3                       No                                  No   \n",
       "4                       No                                  No   \n",
       "\n",
       "  No_of_previous_employers  Promoted_or_Not  \n",
       "0                        0                0  \n",
       "1                        0                0  \n",
       "2                        0                0  \n",
       "3                        1                0  \n",
       "4                        1                0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('./data/promotion/train.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a \n",
    "import datetime\n",
    "df['age'] = datetime.date.today().year - df['Year_of_birth']\n",
    "\n",
    "df['age_on_job'] = datetime.date.today().year - df['Year_of_recruitment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecceasry columns\n",
    "df = df.drop(['EmployeeNo','Year_of_birth','Year_of_recruitment','Qualification'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 'more than 5' with '6'\n",
    "df['No_of_previous_employers'] = df['No_of_previous_employers'].replace('More than 5','6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Channel_of_Recruitment</th>\n",
       "      <th>Trainings_Attended</th>\n",
       "      <th>Last_performance_score</th>\n",
       "      <th>Targets_met</th>\n",
       "      <th>Previous_Award</th>\n",
       "      <th>Training_score_average</th>\n",
       "      <th>State_Of_Origin</th>\n",
       "      <th>Foreign_schooled</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Past_Disciplinary_Action</th>\n",
       "      <th>Previous_IntraDepartmental_Movement</th>\n",
       "      <th>No_of_previous_employers</th>\n",
       "      <th>Promoted_or_Not</th>\n",
       "      <th>age</th>\n",
       "      <th>age_on_job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>Female</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>ANAMBRA</td>\n",
       "      <td>No</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Support and Field Operations</td>\n",
       "      <td>Male</td>\n",
       "      <td>Agency and others</td>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>ANAMBRA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>Male</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>KATSINA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Commercial Sales and Marketing</td>\n",
       "      <td>Male</td>\n",
       "      <td>Agency and others</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>NIGER</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Single</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Information and Strategy</td>\n",
       "      <td>Male</td>\n",
       "      <td>Direct Internal process</td>\n",
       "      <td>3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>AKWA IBOM</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Division  Gender   Channel_of_Recruitment  \\\n",
       "0         Commercial Sales and Marketing  Female  Direct Internal process   \n",
       "1  Customer Support and Field Operations    Male        Agency and others   \n",
       "2         Commercial Sales and Marketing    Male  Direct Internal process   \n",
       "3         Commercial Sales and Marketing    Male        Agency and others   \n",
       "4               Information and Strategy    Male  Direct Internal process   \n",
       "\n",
       "   Trainings_Attended  Last_performance_score  Targets_met  Previous_Award  \\\n",
       "0                   2                    12.5            1               0   \n",
       "1                   2                    12.5            0               0   \n",
       "2                   2                     7.5            0               0   \n",
       "3                   3                     2.5            0               0   \n",
       "4                   3                     7.5            0               0   \n",
       "\n",
       "   Training_score_average State_Of_Origin Foreign_schooled Marital_Status  \\\n",
       "0                      41         ANAMBRA               No        Married   \n",
       "1                      52         ANAMBRA              Yes        Married   \n",
       "2                      42         KATSINA              Yes        Married   \n",
       "3                      42           NIGER              Yes         Single   \n",
       "4                      77       AKWA IBOM              Yes        Married   \n",
       "\n",
       "  Past_Disciplinary_Action Previous_IntraDepartmental_Movement  \\\n",
       "0                       No                                  No   \n",
       "1                       No                                  No   \n",
       "2                       No                                  No   \n",
       "3                       No                                  No   \n",
       "4                       No                                  No   \n",
       "\n",
       "  No_of_previous_employers  Promoted_or_Not  age  age_on_job  \n",
       "0                        0                0   36          11  \n",
       "1                        0                0   31           7  \n",
       "2                        0                0   35          10  \n",
       "3                        1                0   40          13  \n",
       "4                        1                0   32          10  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Division                               0\n",
       "Gender                                 0\n",
       "Channel_of_Recruitment                 0\n",
       "Trainings_Attended                     0\n",
       "Last_performance_score                 0\n",
       "Targets_met                            0\n",
       "Previous_Award                         0\n",
       "Training_score_average                 0\n",
       "State_Of_Origin                        0\n",
       "Foreign_schooled                       0\n",
       "Marital_Status                         0\n",
       "Past_Disciplinary_Action               0\n",
       "Previous_IntraDepartmental_Movement    0\n",
       "No_of_previous_employers               0\n",
       "Promoted_or_Not                        0\n",
       "age                                    0\n",
       "age_on_job                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38312, 17)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "y = df.Promoted_or_Not\n",
    "X = df.drop(['Promoted_or_Not'],axis=1)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodings\n",
    "\n",
    "#use the Onehotencoder for the Division,Gender,Channel_of_Recruitment\n",
    "import category_encoders as ce\n",
    "one_hot = ce.OneHotEncoder(cols=['Division','Gender','Channel_of_Recruitment'])\n",
    "\n",
    "ord_enode = ce.OrdinalEncoder(cols=['Foreign_schooled',\n",
    "                                     'Past_Disciplinary_Action','Previous_IntraDepartmental_Movement'])\n",
    "\n",
    "base_encode = ce.BaseNEncoder(cols=['State_Of_Origin','Marital_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.No_of_previous_employers = df.No_of_previous_employers.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Division                                object\n",
       "Gender                                  object\n",
       "Channel_of_Recruitment                  object\n",
       "Trainings_Attended                       int64\n",
       "Last_performance_score                 float64\n",
       "Targets_met                              int64\n",
       "Previous_Award                           int64\n",
       "Training_score_average                   int64\n",
       "State_Of_Origin                         object\n",
       "Foreign_schooled                        object\n",
       "Marital_Status                          object\n",
       "Past_Disciplinary_Action                object\n",
       "Previous_IntraDepartmental_Movement     object\n",
       "No_of_previous_employers                 int64\n",
       "Promoted_or_Not                          int64\n",
       "age                                      int64\n",
       "age_on_job                               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode y_train\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/envs/test/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('one_hot',\n",
       "                 OneHotEncoder(cols=['Division', 'Gender',\n",
       "                                     'Channel_of_Recruitment'])),\n",
       "                ('ordinal_encode',\n",
       "                 OrdinalEncoder(cols=['Foreign_schooled',\n",
       "                                      'Past_Disciplinary_Action',\n",
       "                                      'Previous_IntraDepartmental_Movement'],\n",
       "                                mapping=[{'col': 'Foreign_schooled',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': Yes    1\n",
       "No     2\n",
       "NaN   -2\n",
       "dtype: int64},\n",
       "                                         {'col': 'Past_Disciplinary_Action',\n",
       "                                          'dat...\n",
       " 23                  0                  1                  1   \n",
       " 24                  1                  0                  0   \n",
       " 25                  1                  0                  0   \n",
       " 26                  1                  0                  1   \n",
       " 27                  1                  0                  1   \n",
       " 28                  1                  1                  0   \n",
       " 29                  1                  1                  0   \n",
       " 30                  1                  1                  1   \n",
       " 31                  1                  1                  1   \n",
       " 32                  0                  0                  0   \n",
       " 33                  0                  0                  0   \n",
       " 34                  0                  0                  1   \n",
       " 35                  0                  0                  1   \n",
       " 36                  0                  1                  0   \n",
       " 37                  0                  1                  0   \n",
       "-1                   0                  0                  0   \n",
       "-2                   0                  0                  0   \n",
       "\n",
       "     State_Of_Origin_6  \n",
       " 1                   1  \n",
       " 2                   0  \n",
       " 3                   1  \n",
       " 4                   0  \n",
       " 5                   1  \n",
       " 6                   0  \n",
       " 7                   1  \n",
       " 8                   0  \n",
       " 9                   1  \n",
       " 10                  0  \n",
       " 11                  1  \n",
       " 12                  0  \n",
       " 13                  1  \n",
       " 14                  0  \n",
       " 15                  1  \n",
       " 16                  0  \n",
       " 17                  1  \n",
       " 18                  0  \n",
       " 19                  1  \n",
       " 20                  0  \n",
       " 21                  1  \n",
       " 22                  0  \n",
       " 23                  1  \n",
       " 24                  0  \n",
       " 25                  1  \n",
       " 26                  0  \n",
       " 27                  1  \n",
       " 28                  0  \n",
       " 29                  1  \n",
       " 30                  0  \n",
       " 31                  1  \n",
       " 32                  0  \n",
       " 33                  1  \n",
       " 34                  0  \n",
       " 35                  1  \n",
       " 36                  0  \n",
       " 37                  1  \n",
       "-1                   0  \n",
       "-2                   0  },\n",
       "                                       {'col': 'Marital_Status',\n",
       "                                        'mapping':     Marital_Status_0  Marital_Status_1  Marital_Status_2\n",
       " 1                 0                 0                 1\n",
       " 2                 0                 1                 0\n",
       " 3                 0                 1                 1\n",
       "-1                 0                 0                 0\n",
       "-2                 0                 0                 0}])),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#build the pipeline\n",
    "pipe = Pipeline(steps=[('one_hot', one_hot), \n",
    "                ('ordinal_encode', ord_enode),\n",
    "               ('base_encode', base_encode),\n",
    "               ('model', lr)])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9173952760015661"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "preds = pipe.predict(X_test)\n",
    "\n",
    "f1_score(y_test,preds,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
