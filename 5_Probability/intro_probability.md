# Probability

- **Def.** a method quantifying the likelihood of an event occurring

    - **Probability:** the likelihood of a given event
        "the areas of a fixed distribution"
    - **Likelihood:** the probability of an event given a history/context of previous behaviours
        "only works with conditions"
        "the definition of the distribution (axis)"
    - **Sample space:** all possible observations / the balls inside your bag
    - **Random variable:** the way you decide to map the observations to reality `ùëã : ùëÜ ‚Üí ‚Ñù`
    - **continues distribution** has infinite amount of numbers/possibilities
    - **discrete distribution** has finite amount of numbers/possibilities
        - Note: you cannot combine continues with discrete distributions
    - **Marginal distribution** the combined probability of multiple variables (to save space)
    - **Chain rule** applied for probability of an event given multiple events (variables) (diff. datas)
    - **Expected value** = mean
    - **Variance:** the measure of spread in a sample
    - **Covariance:** the relationship (aka normalised correlation) between two events
    - **Dirac Distribution:** example: Zooming into an image by sharpening a pixel (i.e. grey) surrounded by other pixels (i.e. green)
    - **Markov chains** awesome for predicting behaviour over time based on others