{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_day4_LanguageGeneration",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5RQVK53AHDYN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil # shell utilities\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import models, layers\n",
        "from tqdm import tqdm # progress indicator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Where the text files are going to live.\n",
        "dataset_path = \"dataset\"\n",
        "dataset_path_all = os.path.join(dataset_path, \"all\")\n",
        "dataset_path_train = os.path.join(dataset_path, \"train\")\n",
        "dataset_path_valid = os.path.join(dataset_path, \"valid\")\n",
        "\n",
        "# Just use 20 files.\n",
        "file_number = 20\n",
        "\n",
        "# Gather the corpus if it has not been gathered yet.\n",
        "if not os.path.exists(dataset_path):\n",
        "\n",
        "    # Create all the folders.\n",
        "    for path in [dataset_path, dataset_path_all, dataset_path_train, dataset_path_valid]:\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "\n",
        "    # Clone the repo.\n",
        "    #!git clone https://github.com/vilmibm/lovecraftcorpus\n",
        "        \n",
        "    # Find all the files.\n",
        "    #paths_all = glob.glob(\"lovecraftcorpus/*.txt\")\n",
        "    \n",
        "    print(sorted(paths_all))\n",
        "\n",
        "    # Do not use all.\n",
        "    paths_all = paths_all[:file_number]\n",
        "\n",
        "    # Split 80/20.\n",
        "    split_index = int(len(paths_all) * 0.8)\n",
        "    paths_train = paths_all[:split_index]\n",
        "    paths_valid = paths_all[split_index:]\n",
        "\n",
        "    # Copy files.\n",
        "    def copy(paths, destination):\n",
        "        for path in paths:\n",
        "            shutil.copy2(path, destination)\n",
        "    copy(paths_all, dataset_path_all)\n",
        "    copy(paths_train, dataset_path_train)\n",
        "    copy(paths_valid, dataset_path_valid)\n",
        "\n",
        "    # Delete repo.\n",
        "    !rm -rf lovecraftcorpus\n",
        "\n",
        "    # Done.\n",
        "    print(\"Corpus downloaded.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "KCxqNrlEHJDg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls dataset\n",
        "print(\"\")\n",
        "!ls dataset/all\n",
        "print(\"\")\n",
        "!ls dataset/train\n",
        "print(\"\")\n",
        "!ls dataset/valid\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXINTHqDHOWw",
        "outputId": "59395222-dd01-4a51-a55f-99077e33cc83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all  train  valid\n",
            "\n",
            "'(Book) - Cookbook - Nelson Family Recipe Book_djvu.txt'\n",
            "'Cookbook - Fish & Game Recipes_djvu.txt'\n",
            "'Cookbook - Fish Recipes_djvu.txt'\n",
            "'Cooking - 200 Recipes for Italian Dishes_djvu.txt'\n",
            "'Cooking - Soup Recipes_djvu.txt'\n",
            "'(ebook) Food - Vegetable Recipes_djvu.txt'\n",
            "'(ebook-pdf) - Cooking - Italian Recipes_djvu.txt'\n",
            "'(ebook-pdf) - Cooking - Low Fat Recipes_djvu.txt'\n",
            "'(ebook-pdf) - Cooking - Salad Recipes (1)_djvu.txt'\n",
            "'E-Cookbooks Italian Recipe Sampler_djvu.txt'\n",
            "'E-Cookbooks Low Fat Recipe Sampler_djvu.txt'\n",
            "'E-Cookbooks Salads Recipes_djvu.txt'\n",
            "'Italian Recipes_djvu.txt'\n",
            "'Lifestyle to Health - Vegan  Cookbook Recipes, vegetarian health book_djvu.txt'\n",
            "\n",
            "'(Book) - Cookbook - Nelson Family Recipe Book_djvu.txt'\n",
            "'Cookbook - Fish & Game Recipes_djvu.txt'\n",
            "'Cookbook - Fish Recipes_djvu.txt'\n",
            "'Cooking - 200 Recipes for Italian Dishes_djvu.txt'\n",
            "'Cooking - Soup Recipes_djvu.txt'\n",
            "'(ebook) Food - Vegetable Recipes_djvu.txt'\n",
            "'(ebook-pdf) - Cooking - Italian Recipes_djvu.txt'\n",
            "'(ebook-pdf) - Cooking - Low Fat Recipes_djvu.txt'\n",
            "'(ebook-pdf) - Cooking - Salad Recipes (1)_djvu.txt'\n",
            "'E-Cookbooks Italian Recipe Sampler_djvu.txt'\n",
            "'E-Cookbooks Low Fat Recipe Sampler_djvu.txt'\n",
            "\n",
            "'E-Cookbooks Salads Recipes_djvu.txt'\n",
            "'Italian Recipes_djvu.txt'\n",
            "'Lifestyle to Health - Vegan  Cookbook Recipes, vegetarian health book_djvu.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare datasets"
      ],
      "metadata": {
        "id": "9hdx4XSxDgtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "def create_dataset(dataset_path):\n",
        "  dataset = preprocessing.text_dataset_from_directory( # turns file system into dataset\n",
        "      dataset_path, \n",
        "      labels=None,\n",
        "      batch_size=batch_size,\n",
        "      seed=seed\n",
        "  )\n",
        "  return dataset\n",
        "\n",
        "dataset_original_all = create_dataset(dataset_path_all)\n",
        "dataset_original_train = create_dataset(dataset_path_train)\n",
        "dataset_original_valid = create_dataset(dataset_path_valid)\n"
      ],
      "metadata": {
        "id": "eyJPza8hHOuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b18ba03-e1a2-41c5-f6c1-58ad185490e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14 files belonging to 1 classes.\n",
            "Found 11 files belonging to 1 classes.\n",
            "Found 3 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if files work\n",
        "for batch in dataset_original_all:\n",
        "  for sample in batch[:4]:\n",
        "    sample = sample.numpy()\n",
        "    print(sample[:200], \"...\")\n",
        "    print(len(sample), \"bytes\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_sG3L51D1C8",
        "outputId": "c0e1fcab-5016-4464-d5bd-9b625437acd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\nTHE FOOD AND COOKING NETWORK \\n\\n\\n\\nE-Cookbooks Soup Recipe Sampler \\n\\nVJJE Publishing Co. \\n\\n\\n\\nE-Cookbooks Soup Recipe Sampler \\n\\nTable of Contents \\n\\nIntroduction 1 \\n\\nPersonalized Cooking Aprons 2 \\n\\nBasic' ...\n",
            "22103 bytes\n",
            "\n",
            "b'Vegetable (loosely) Recipes \\n\\nVegetable (loosely) Recipes \\n\\n\\n\\nIndex \\n\\n\\n\\n\\xe2\\x80\\xa2 \\n\\n\\nGreen/Red Peppers : INDEX \\n\\n\\n\\xe2\\x80\\xa2 \\n\\n\\nMushrooms : INDEX \\n\\n\\n\\xe2\\x80\\xa2 \\n\\n\\nPotatoes : INDEX \\n\\n\\n\\xe2\\x80\\xa2 \\n\\n\\nSpinach : INDEX \\n\\n\\n\\xe2\\x80\\xa2 \\n\\n\\nVege' ...\n",
            "260275 bytes\n",
            "\n",
            "b'Cooking - 200 Recipes for Italian Dishes (Share Me).txt \\nThe Cook\\'s Decameron: A Study In Taste \\n\\nContaining Over Two Hundred Recipes For Italian Dishes \\n\\nBy \\n\\nMrs. w. G. waters \\n\\n\"Show me a pleasure ' ...\n",
            "270098 bytes\n",
            "\n",
            "b'Nelson Family \\nRecipe Book \\n\\nTable Of Contents \\n\\n\\n\\nBreads 3 \\n\\nSoups 15 \\n\\nVegetables 23 \\n\\nSalads 29 \\n\\nMain Dishes 39 \\n\\nCake & Frostings 65 \\n\\nCookies, Bars, and Lefse 75 \\n\\nPies & Desserts 93 \\n\\nBeverages' ...\n",
            "171324 bytes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the tokenizer"
      ],
      "metadata": {
        "id": "bVxL8MCpGqz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 5000 # 10.000 is very limited, just for exercise shake\n",
        "\n",
        "encoder = layers.TextVectorization(\n",
        "    max_tokens=vocabulary_size,\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"int\" # word indices with respect to vocabulary | no sequence length!\n",
        ")\n",
        "encoder.adapt(dataset_original_all) # we cannot batch\n",
        "\n",
        "vocabulary = encoder.get_vocabulary()\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocabulary)}\")\n",
        "print(f\"Vocabulary: {vocabulary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM2JkI8oFxS6",
        "outputId": "3555db76-9243-4cd9-860e-77ec38575567"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 5000\n",
            "Vocabulary: ['', '[UNK]', 'and', 'the', 'a', '1', 'of', 'in', 'to', 'with', '2', 'cup', 'or', 'for', 'add', '12', 'salt', 'until', 'minutes', 'it', 'c', 'water', 'sauce', 'pepper', 'butter', 'into', 'chopped', 'on', 'i', 'is', 'teaspoon', 'o', '14', 'over', '3', 'tsp', 'cheese', 'ingredients', 'oil', 'cups', 'garlic', 'onion', 'flour', 'heat', 'at', 'cook', 'them', 'mix', 'from', 'as', 'sugar', 'you', 'then', 'cut', '4', 'about', 'this', 'all', 'cream', 'large', 'bake', 'mixture', 'serve', 'be', 'pan', 'that', 'well', 'can', 'vi', 'put', 'no', 'stir', 'juice', 'chicken', 'tablespoons', 'if', 'eggs', 'are', 'place', 'salad', 'bowl', 'an', 'pour', 'mushrooms', 'fresh', 'one', 'cooking', 'bread', 'potatoes', 'small', 'parsley', 'milk', 'up', 'lemon', 'brown', 'hot', 'tomatoes', 'egg', 'boil', 'stock', 'when', 'cover', 'two', 'cooked', 'taste', 'recipes', 'alia', 'powder', 'oven', 'half', 'onions', 'combine', 'fish', 'dish', 'oz', 'top', 'olive', 'little', '5', 'have', 'medium', 'but', 'rice', 'tbsp', 'not', 'soup', 'remove', '6', '8', 'tablespoon', 'each', 'tomato', 'let', 'grated', '10', 'ground', '•', 'together', 'baking', 'sprinkle', 'sliced', 'good', '13', 'italian', 'red', 'out', 'by', 'green', 'white', 'pound', '34', 'use', 'slices', 'make', 'dry', 'more', 'some', 'simmer', 'remaining', 'will', 'drain', 'they', 'hour', 'parmesan', 'celery', 'before', 'beans', 'minced', 'vinegar', 'cool', '15', 'recipe', 'set', 'black', '20', 'potato', 'beef', 'was', 'saute', 'bacon', 'pm', 'diced', 'cloves', 'just', 'tender', 'pasta', 'off', 'very', 'so', 'ham', 'pieces', 'zucchini', 'whole', 'dough', 'hours', 'bring', 'warm', 'stirring', 'which', 'serving', 'may', 'teaspoons', 'vanilla', '350°', 'crumbs', 'blend', 'dressing', 'corn', 'cold', '12171999', 'through', 'skillet', 'meat', 'fry', 'finely', 'collection', 'tblsp', 'spread', 'we', 'vegetables', 'ounces', 'boiling', 'said', '18', 'eggplant', 'saucepan', '30', '23', 'your', 'thick', 'peppers', 'honey', 'dishes', 'wine', 'three', 'mushroom', 'food', 'carrots', 'aside', 'low', 'fat', 'enough', 'should', 'like', 'layer', 'crushed', 'basil', 'lightly', 'dried', 'cake', 'had', 'few', 'sweet', 'other', 'olives', 'smooth', 'beat', 'pie', 'leaves', 'he', 'any', 'roll', 'nuts', 'stuffed', 'di', 'take', 'reduce', 'garnish', 'margarine', 'l', 'slice', 'peel', 'liquid', 'do', 'has', 'tofu', 'my', 'cinnamon', 'side', 'inch', 'casserole', 'herbs', 'baked', 'time', 'mustard', 'spoon', 'shredded', 'season', 'orange', 'his', 'while', 'melted', 'instructions', 'chili', 'peeled', 'mrs', 'frozen', 'bay', 'roast', 'yeast', 'turn', 'cornstarch', 'pot', 'lb', 'broth', 'pineapple', 'her', 'soft', 'squash', 'soy', 'sausage', 'clove', 'beaten', 'another', 'raisins', 'drained', '9', 'chocolate', 'bottom', 'blender', 'after', 'fruit', 'yogurt', 'seeds', 'package', 'ounce', 'lettuce', 'dip', 'been', 'using', 'page', 'mayonnaise', 'veal', 'keep', 'golden', '45', '200', 'vegetable', 'share', 'get', 'carrot', 'refrigerate', 'paste', 'paprika', 'fillets', 'its', 'covered', '7', 'gravy', 'fowl', 'desired', 'apples', 'almonds', 'would', 'wheat', 'than', 'four', '16', 'thyme', 'metxt', 'made', 'fine', 'avocado', 'these', 'spray', 'spinach', 'marchesa', 'chill', 'slightly', 'form', 'filling', 'arrange', 'toss', 'leaf', '25', 'x', 'too', 'seasoning', 'first', 'done', 'also', 'cheddar', 'turkey', 'sheet', 'paper', 'high', 'free', 'day', 'browned', 'soda', 'pinch', 'macaroni', 'down', 'chips', 'allow', 'preheat', 'melt', '21', 'start', 'prepare', 'our', 'flakes', 'sir', 'nutmeg', 'truffles', 'pounds', 'oregano', 'minute', 'long', 'da', 'crust', 'yolks', 'she', 'john', 'coconut', 'their', 'once', 'mixed', 'spaghetti', 'shape', 'coat', 'chop', 'cayenne', 'thin', 'peas', 'bell', 'stephanie', 'stand', 'silva', 'noodles', 'last', 'heavy', 'gently', 'date', 'size', 'same', 'makes', 'light', 'degrees', 'were', 'fill', 'english', 'bit', 'walnuts', 'sour', 'pork', 'nelson', 'broccoli', 'whites', 'optional', 'glass', 'fried', 'freshly', 'best', 'used', 'spice', 'puree', 'head', 'calfs', 'al', '24', 'oats', 'cumin', 'constantly', 'bits', 'much', 'mozzarella', 'great', 'fork', 'dinner', 'continue', 'boiled', 'salmon', 'e', 'dont', 'breast', 'apple', 't', 'sides', 'raw', 'pass', 'occasionally', 'me', 'forcemeat', 'firm', 'clear', 'cashews', 'cans', 'way', 'strips', 'stop', 'shrimp', 'next', 'what', 'stanley', 'sage', 'pumpkin', 'polenta', 'only', 'here', 'duck', 'cookies', '26', 'who', 'thinly', 'table', 'prepared', 'pint', 'must', 'french', 'skin', 'peanut', 'whisk', 'till', 'temperature', 'processor', 'frying', 'cubes', 'balls', 'wash', 'soak', 'seeded', 'press', 'new', 'vegetarian', 'stems', 'steak', 'overnight', 'oatmeal', 'ice', 'how', 'ginger', 'foil', 'except', 'cucumber', 'cookery', 'bunch', '350', 'spicy', 'now', 'muffins', 'marjoram', 'dash', 'cookie', 'adding', 'sweetbread', 'stewpan', 'searching', 'rest', 'ready', 'powdered', 'meatballs', 'httpwwwecookbooksnet', 'ecookbooks', 'cookbooks', 'chunks', 'under', 'thickened', 'there', 'plain', 'pecans', 'patties', 'note', 'n', 'many', 'f', 'both', 'without', 'venison', 'thoroughly', 'stew', 'shortening', 'round', 'quick', 'onto', 'mixing', 'immediately', 'every', 'dill', 'room', 'nonstick', 'loaf', 'less', 'dates', 'cubed', 'batter', 'wrap', 'va', 'us', 'tbs', 'tahini', 'stuffing', 'sieve', 'necessary', 'mash', 'greased', 'five', 'croutons', 'back', 'sure', 'quite', 'piece', 'mashed', 'cocoa', 'topping', 'tongue', 'tablespoonsful', 'such', 'spices', 'rabbit', 'most', 'microwave', 'longer', 'fold', 'fire', 'colonel', 'canned', 'buttered', '¥2', 'worcestershire', 'want', 'seasoned', 'salted', 's', 'refrigerator', 'plate', 'narcisse', 'knead', 'halves', 'deep', 'center', 'cauliflower', '68', 'sesame', 'roasted', 'leave', 'hand', 'espagnole', 'coffee', 'cilantro', 'between', 'variation', 'ten', 'softened', 'risotto', 'quarter', 'millet', 'lowfat', 'lentils', 'least', 'health', 'game', 'extra', 'contents', '000000000000000000000000000000000000000000000000000000000000000000000000000', 'stuff', 'stick', 'rinse', 'rack', 'possible', 'plastic', 'pastry', 'meal', 'grease', 'gradually', 'g', 'even', 'bean', 'angel', 'amount', '112', 'syrup', 'strawberries', 'servings', 'pizza', 'per', 'drop', 'coriander', 'cherry', 'amyl', 'always', 'again', '11', 'turning', 'rise', 'return', 'quart', 'min', 'lime', 'lifestyle', 'lengthwise', 'juices', 'glaze', 'cooks', 'caramel', 'arielletarongacom', '17', 'see', 'rosemary', 'process', 'pat', 'ooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo', 'nutritional', 'never', 'heated', 'frosting', 'fillet', 'evenly', 'broil', 'around', '40', '35', 'work', 'whip', 'toasted', 'sampler', 'pudding', 'plates', 'mueller', 'marinate', 'greens', 'gnocchi', 'end', 'curry', 'creamy', 'crab', 'chablis', 'wild', 'style', 'steam', 'source', 'slowly', 'rolls', 'ng', 'need', 'halved', 'following', 'fatfree', 'could', 'cooled', 'am', 'allpurpose', 'above', '1993', 'uncovered', 'tarragon', 'tablespoonful', 'shallow', 'serves', 'seafood', 'reserve', 'reduced', 'pine', 'part', 'opt', 'often', 'lasagna', 'jar', 'inside', 'equal', 'cutlets', 'breasts', 'better', 'bars', 'aprons', '50', '350f', 'where', 'usually', 'transfer', 'squeeze', 'sole', 'sinclair', 'sherry', 'pita', 'lunch', 'livers', 'give', 'double', 'crisp', 'completely', 'buttermilk', 'blended', 'along', 'additional', '56', 'yellow', 'tortilla', 'times', 'surface', 'still', 'sticks', 'rolled', 'kim', 'instead', 'inches', 'carob', 'brains', 'almond', '71', '22', 'van', 'skim', 'several', 'removed', 'personalized', 'people', 'muffin', 'molasses', 'mediumhigh', 'marinade', 'know', 'hard', 'evaporated', 'enjoy', 'easy', 'clean', 'breakfast', 'being', 'avocados', '27', 'wholewheat', 'toney', 'strawberry', 'seasonings', 'salsa', 'rhubarb', 'pheasant', 'old', 'mint', 'might', 'mi', 'lower', 'go', 'full', 'everything', 'either', 'drizzle', 'crackers', 'brush', 'biscuits', 'basic', 'balsamic', 'artichoke', '19', 'think', 'shell', 'romano', 'platter', 'parmigiana', 'oysters', 'needed', 'mould', 'menu', 'marsala', 'layers', 'frequently', 'floured', 'favorite', 'eat', 'crumbled', 'comes', 'because', 'anchovy', 'according', 'zuchinni', 'unsweetened', 'toast', 'store', 'slow', 'roasting', 'pi', 'nut', 'line', 'greek', 'gradinger', 'flat', 'divide', 'directions', 'der', 'cornmeal', 'container', 'consistency', 'come', 'caps', 'bouillon', 'blanch', 'bananas', 'artichokes', 'anchovies', '46', '00000', 'whiz', 'unsalted', 'trout', 'tops', 'teaspoonful', 'steaks', 'sprayed', 'soaked', 'shells', 'served', 'separate', 'seconds', 'ribs', 'reserved', 'really', 'him', 'hamburger', 'grill', 'grape', 'discard', 'delicious', 'ball', 'works', 'upon', 'thawed', 'six', 'shallots', 'say', 'repeat', 'peppercorns', 'peaches', 'marinated', 'jalapeno', 'granola', 'find', 'eggplants', 'dijon', 'deb', 'board', 'bag', 'applesauce', '60', '55', 'vinaigrette', 'uncooked', 'those', 'split', 'smoked', 'sit', 'seed', 'roet', 'ripe', 'ricotta', 'regular', 'raspberry', 'pressed', 'point', 'pitted', 'pimento', 'order', 'morning', 'measure', 'goose', 'gmt', 'days', 'crumb', 'break', 'banana', 'added', '999', '93', 'wooden', 'vitello', 'unbleached', 'towel', 'taco', 'something', 'packages', 'making', 'liver', 'jacobson', 'j', 'hands', 'hair', 'german', 'found', 'family', 'dissolve', 'chops', 'bragg', 'boneless', 'bechamel', 'absorbed', '375°', '36', 'velute', 'swiss', 'stalks', 'square', 'preheated', 'pink', 'packed', 'own', 'look', 'lbs', 'lay', 'knife', 'keil', 'jello', 'jam', 'grapefruit', 'excess', 'dark', 'christa', 'carefully', 'breadcrumbs', 'bone', 'big', 'aminos', '—', '¥i', 'yolk', 'wide', 'week', 'walnut', 'sharp', 'pkg', 'pans', 'lean', 'kidney', 'individual', 'index', 'httpwwwxsxmuedumjwrecipesvegetablesmushroomsmushcollhtml', 'fit', 'dissolved', 'con', 'coated', 'cider', 'chowder', 'capers', 'briefly', 'blueberries', '32', 'world', 'wipe', 'thicken', 'sauces', 'rinsed', 'quarts', 'pecan', 'outside', 'name', 'ml', 'ltsp', 'jelly', 'insalata', 'home', 'hearts', 'gelatin', 'friend', 'fowls', 'extract', 'dear', 'coarsely', 'cashew', 'cabbage', 'broiler', 'begins', 'away', '57', '28', 'yl', 'yields', 'whipped', 'variety', 'tabasco', 'sift', 'salami', 'rounds', 'quickly', 'omelette', 'mullet', 'moderate', 'method', 'meanwhile', 'm', 'left', 'lamb', 'lady', 'ever', 'does', 'bulgur', 'blue', 'barbecue', 'antipasto', 'allspice', '51', '48', '33', '1015', 'weed', 'villeroy', 'truffle', 'trim', 'towels', 'torn', 'strain', 'spoonful', 'soups', 'si', 'scoop', 'rings', 'rind', 'relish', 'rather', 'quarters', 'quantities', 'oyster', 'oranges', 'mutton', 'miss', 'milanese', 'manzo', 'loaves', 'kitchen', 'kale', 'joyce', 'introduction', 'gratin', 'graham', 'freeze', 'flavors', 'flavor', 'fireproof', 'excellent', 'dutch', 'dust', 'drippings', 'dice', 'cucumbers', 'cranberry', 'cranberries', 'colour', 'careful', 'burgundy', 'bubbly', 'blueberry', 'bisque', 'beet', 'asparagus', '74', '47', '29', 'wire', 'though', 'supreme', 'sunflower', 'stiff', 'starch', 'squid', 'spring', 'simple', 'show', 'separately', 'semolina', 'rich', 'quartered', 'mixer', 'melts', 'lobster', 'ketchup', 'idea', 'gary', 'forms', 'during', 'd', 'crockpot', 'cracker', 'cod', 'cloth', 'cavity', 'burn', 'become', 'aluminum', 'almost', '54', '52', '44', '42', '37', '1520', 'wilding', 'vjje', 'twenty', 'try', 'tea', 'taken', 'speed', 'rub', 'raise', 'pickles', 'mom', 'macdonnell', 'leaving', 'la', 'im', 'httpwwwcscmuedumjwrecipesvegetablespotatopotcollhtml', 'harriet', 'glazed', 'frittata', 'feta', 'eaten', 'dessertspoonful', 'dessert', 'dente', 'cube', 'couple', 'click', 'choose', 'certain', 'cereal', 'castor', 'box', 'blanched', 'begin', 'apricots', '9x13', '70', '53', '49', 'wont', 'vz', 'v', 'tightly', 'throw', 'subscribe', 'shall', 'seems', 'sauteed', 'salads', 'romaine', 'raspberries', 'quantity', 'quality', 'omit', 'mediumlow', 'lid', 'lard', 'kounovsky', 'kathryn', 'ingredient', 'ii', 'herb', 'fothergill', 'flavour', 'fingers', 'doubled', 'couscous', 'considine', 'color', 'cm', 'chives', 'chile', 'cherries', 'cheesecake', 'candy', 'braize', 'boston', 'bill', 'air', 'across', '67', '58', '43', '31', '300°', 'whisking', 'w', 'virgin', 'velveeta', 'veggie', 'torta', 'tenderloin', 'substitute', 'stewed', 'sprigs', 'sort', 'sirloin', 'sheets', 'shake', 'sep', 'sea', 'scallops', 'right', 'richard', 'randal', 'r', 'purpose', 'open', 'oat', 'nice', 'nearly', 'marshmallows', 'market', 'mandarin', 'man', 'library', 'lentil', 'iron', 'httpwwwxsxmuedumjwrecipesvegetableszuchinnizuchinnicoll2html', 'heads', 'got', 'given', 'genovese', 'dredge', 'doreen', 'did', 'decorate', 'course', 'circle', 'chilies', 'chef', 'charcoal', 'champagne', 'cast', 'brain', 'bones', 'baste', 'bass', 'approximately', 'allltaliana', '72', '400', '375f', 'zuppa', 'wok', 'why', 'wet', 'watch', 'washed', 'ungreased', 'tins', 'tell', 'steamed', 'skinless', 'sifted', 'salmone', 'reserving', 'removing', 'plum', 'piquante', 'pigeons', 'perhaps', 'mush', 'mold', 'med', 'mara', 'madeira', 'larger', 'instant', 'indeed', 'increase', 'heart', 'halfandhalf', 'gladys', 'freezer', 'eunice', 'ends', 'electric', 'elds', 'eating', 'diameter', 'cutup', 'cutting', 'curried', 'core', 'class', 'chutney', 'chilled', 'chervil', 'cheeses', 'century', 'catfish', 'casalinga', 'cardamom', 'cakes', 'bowls', 'bainmarie', 'american', 'admirable', '97', '90', '80', '41', '400°', '3040', '105', 'zukes', 'wedges', 'v2', 'uova', 'unti', 'unpeeled', 'tiny', 'thu', 'thickness', 'taking', 'spoonsful', 'souffle', 'sandwiches', 'rolling', 'provolone', 'portion', 'pomidoro', 'pig', 'perfect', 'peppermint', 'peanuts', 'party', 'partially', 'pantke', 'pack', 'otherwise', 'nutes', 'night', 'mins', 'minestra', 'mine', 'micaela', 'meantime', 'mask', 'mace', 'liquor', 'life', 'lc', 'jul', 'hold', 'grate', 'gave', 'frost', 'follow', 'flesh', 'flake', 'fact', 'eyes', 'etc', 'dozen', 'crispy', 'continued', 'company', 'cocks', 'choice', 'centre', 'came', 'buns', 'bulgar', 'browning', 'brandy', 'au', 'animelle', 'afternoon', 'adjust', '81', '78', '77', '75', '73', '65', '400f', 'year', 'whiting', 'weekly', 'vegesal', 'undrained', 'u', 'turnips', 'tray', 'thermometer', 'texture', 'tendons', 'tartar', 'sufficiently', 'strew', 'stalk', 'sprig', 'sogliole', 'shapes', 'shallot', 'second', 'rump', 'pulp', 'proof', 'prefer', 'popular', 'popcorn', 'parts', 'number', 'notes', 'nori', 'ne', 'maraschino', 'lukewarm', 'kettle', 'including', 'house', 'hare', 'h', 'guests', 'grilled', 'et', 'divided', 'depending', 'de', 'concentrate', 'combs', 'colander', 'cavatelli', 'care', 'broken', 'beets', 'beetroot', 'bar', 'art', '810', '79', '69', '61', '59', '39', 'yourself', 'watercress', 'visible', 'veggies', 'uncover', 'tiramisu', 'thickens', 'testa', 'stove', 'squares', 'spanish', 'somewhat', 'smaller', 'since', 'simmering', 'short', 'school', 'run', 'require', 'reason', 'ranch', 'prunes', 'preparation', 'poppy', 'plus', 'piri', 'palate', 'ones', 'oct', 'middle', 'means', 'mar', 'manicotti', 'machine', 'lot', 'lines', 'kind', 'jars', 'jack', 'ive', 'italy', 'httpwwwcscmuedumjwrecipesvegetableseggplantcollhtml', 'having', 'grind', 'going', 'garden', 'fruits', 'focaccia', 'finish', 'finger', 'fettucini', 'evangelos', 'else', 'edges', 'dressed', 'doussis', 'desserts', 'degree', 'deg', 'cottage', 'coloring', 'chickenstyle', 'chestnuts', 'ce', 'catch', 'cajun', 'cabernet', 'burgers', 'brownies', 'book', 'beer', 'arrowroot', 'anything', 'anyone', 'already', '82', '63', '38', '325°', '2025', '121', 'ziti', 'zest', 'yield', 'years', 'y', 'whatever', 'wax', 'twice', 'turned', 'tureen', 'trouble', 'trimmed', 'tortellini', 'topped', 'took', 'thus', 'third', 'tenerumi', 'tear', 'tastes', 'tasted', 'spinaci', 'snap', 'slotted', 'slivered', 'skinned', 'seemed', 'scallions', 'savoury', 'save', 'sandwich', 'saffron', 'rum', 'roma', 'ring', 'radishes', 'properly', 'polio', 'pleasant', 'pistacchio', 'peach', 'patty', 'pate', 'oiled', 'neapolitan', 'mortar', 'main', 'ltbsp', 'lots', 'loosen', 'kiwi', 'important', 'icing', 'httpwwwcscmuedumjwrecipesvegetablesavocadocollhtml', 'however', 'halibut', 'granulated', 'gone', 'gift', 'generally', 'garbanzo', 'flavouring', 'fiorentina', 'finally', 'fashion', 'fairly', 'ents', 'england', 'endive', 'email', 'eight', 'effort', 'edge', 'dolores', 'dinners', 'delight', 'delicate', 'darsie', 'cuttings', 'curls', 'crosswise', 'crema', 'chipotle', 'cervello', 'case', 'carmen', 'cannot', 'buy', 'button', 'birds', 'biddle', 'berries', 'beginning', 'base', 'baby', 'amounts', 'alternately', 'ahead', 'account', 'absorb', '99', '1inch', '190', '125', 'young', 'youll', 'wish', 'winter', 'went', 'vonne', 'visit', 'veneziana', 'vary', 'variations', 'tube', 'ts', 'true', 'tried', 'tortillas', 'tongues', 'title', 'tie', 'therefore', 'thats', 'task', 'takes', 'sweetbreads', 'sullivan', 'suggest', 'sugars', 'sucking', 'starting', 'sprouts', 'spiced', 'species', 'soon', 'soften', 'shellfish', 'shaking', 'separated', 'rye', 'romana', 'replace', 'remain', 'real', 'read', 'quail', 'punch', 'pull', 'preferred', 'preferably', 'portions', 'port', 'perch', 'peaks', 'ox', 'nz', 'moderately', 'mill', 'masking', 'maple', 'manner', 'loosely', 'london', 'livornese', 'legs', 'leeks', 'lambs', 'ladle', 'kept', 'horseradish', 'holiday', 'heard', 'handful', 'gourmet', 'glasses', 'gill', 'germany', 'gen', 'gel', 'garl', 'fully', 'fudge', 'flame', 'fennel', 'entrees', 'edu', 'ecookbook', 'dy', 'doesnt', 'crumble', 'crouton', 'cored', 'coloured', 'colorful', 'coarse', 'co', 'clam', 'chuck', 'check', 'caramels', 'capon', 'called', 'call', 'california', 'ca', 'breads', 'bran', 'bottle', 'bitter', 'bird', 'below', 'bath', 'basting', 'barley', 'apart', 'alice', 'able', '88', '86', '66', '64', '62', '325f', '2tbsp', '12inch', '123', '116', '10inch', '1012', '100', 'zabajone', 'zabaglione', 'yoke', 'yet', 'waffles', 'voice', 'vigorously', 'versiliese', 'turns', 'translucent', 'touch', 'tips', 'things', 'themselves', 'tbls', 'summer', 'sticky', 'stem', 'spumone', 'spend', 'spatula', 'sodium', 'society', 'snipe', 'smoothie', 'sheeps', 'sections', 'seal', 'scraping', 'scalloped', 'savory', 'sauerkraut', 'running', 'roman', 'riso', 'restaurant', 'quenelles', 'publishing', 'previously', 'pretty', 'present', 'poultry', 'possum', 'polpette', 'placed', 'pin', 'pickling', 'particular', 'palates', 'ought', 'others', 'oleo', 'oh', 'nto', 'noodle', 'neck', 'near', 'mushy', 'mr', 'moist', 'mind', 'mild', 'mere', 'mass', 'mary', 'marshmallow', 'magazine', 'maddex', 'lemons', 'layered', 'julienned', 'imported', 'imbottiti', 'hope', 'herbed', 'help', 'heaping', 'grapes', 'giordano', 'getting', 'fun', 'fratelli', 'followed', 'fluffy', 'feel', 'fear', 'fast', 'fancy', 'fagioli', 'eye', 'essence', 'ernes', 'entire', 'encourage', 'eastern', 'easily', 'dress', 'diet', 'custard', 'create', 'creamed', 'crayfish', 'crabmeat', 'country', 'cont', 'combining', 'cleaned', 'clams', 'cl', 'chiles', 'chewy', 'cavoli', 'caruso', 'carbonara', 'caprese', 'caponata', 'calves', 'calories', 'calamari', 'bubbles', 'bubble', 'bruschetta', 'bought', 'boned', 'boils', 'bleu', 'blending', 'believe', 'barely', 'aug', 'amigans', 'ala', 'ago', 'addition', 'active', '96', '95', '87', '83', '76', '510', '14inch', '100000', 'zuccini', 'ynnuf', 'yett', 'yesterday', 'words', 'within', 'whether', 'type', 'turmeric', 'treated', 'translation', 'toothpicks', 'threequarters', 'thirty', 'thicker', 'text', 'test', 'teriyaki', 'tart', 'swirl', 'sweetener', 'sunset', 'suggestions', 'stage', 'sprinkled', 'spreads', 'special', 'smoke', 'slaw', 'ski', 'skewers', 'sized', 'similar', 'setting', 'seem', 'section', 'secret', 'roux', 'remember', 'remark', 'reheat', 'puff', 'protect', 'professional', 'produce', 'probably', 'pressure', 'preserved', 'preparing', 'postfach', 'portobello', 'poor', 'pockets', 'pickle', 'perfectly', 'patate', 'partridges', 'pancake', 'p', 'overcook', 'ostriche', 'oriental', 'nonfat', 'ni', 'mud', 'mon', 'moment', 'mississippi', 'meet', 'mediterranean', 'meats', 'mayo', 'masher', 'mademoiselle', 'liquefy', 'learn', 'larding', 'kofta', 'kernel', 'k', 'joint', 'itself', 'inscribe', 'imperial', 'httpwwwcscmuedumjwrecipesvegetablesartichokecollhtml', 'hens', 'hash', 'handle', 'goes', 'gm', 'gluten', 'gills', 'gets', 'germ', 'garbanzos', 'field', 'fans', 'experience', 'envelope', 'entirely', 'entered', 'elbow', 'eel', 'easier', 'drops', 'dot', 'disks', 'deli', 'deal', 'cuts', 'crush', 'crumbly', 'costolette', 'cooker', 'consent', 'combined', 'combination', 'colors', 'close', 'circles', 'cioppino', 'chunky', 'christahorgaruhrde', 'chip', 'chinese', 'certainly', 'catsup', 'castrato', 'carving', 'border', 'bombay', 'bitesize', 'beansauce', 'batches', 'batch', 'barbecued', 'bags', 'b', 'area', 'apron', 'allowed', 'against', 'advance', 'accumulated', '98', '91', '84', '450', '3045', '3035', '121257', '121050', '111', '108', '107', '106', '101312', '0200', '■', 'word', 'worchestershire', 'whilst', 'waxed', 'ui', 'turnip', 'turbot', 'tuna', 'trimmings', 'tossing', 'toothpick', 'today', 'til', 'throughout', 'thousand', 'thinner', 'thing', 'teas', 'teach', 'tapioca', 'swedish', 'suggestion', 'stirfry', 'sticking', 'sti', 'stayka', 'starts', 'st', 'space', 'soybeans', 'sound', 'sorts', 'sorrel', 'sometimes', 'sold', 'slicing', 'single', 'simply', 'sidonie', 'shred', 'shaped', 'septemberoctober', 'secure', 'scrape', 'sausages', 'saucepot', 'sat', 'required', 'refrigerated', 'prick', 'prevent', 'pounded', 'potatos', 'pocket', 'poached', 'plenty', 'pleasure', 'pesto', 'pepperoni', 'pea', 'pattern', 'partridge', 'paris', 'ozs', 'ostrich', 'opened', 'nonreactive', 'natural', 'monterey', 'monkfish', 'mistress', 'mistakes', 'minuta', 'minestrone', 'minestre', 'mexican', 'mean', 'material', 'malai', 'maintain', 'macedoine', 'll', 'linguine', 'lefse', 'later', 'late', 'lasagne', 'lakes', 'ka', 'juccini', 'jacobsonrecipe', 'items', 'isnt', 'indian', 'impossible', 'ill', 'hz225wuuniduiuniduisburgde', 'hungarian', 'httpwwwcscmuedumjwrecipesvegetablessquashcollhtml', 'homemade', 'helps', 'handed', 'grain', 'giardiniera', 'gar', 'fungi', 'friends', 'fridge', 'foamy', 'flours', 'flounder', 'flavoring', 'fits', 'fishing', 'firmly', 'finished', 'fi', 'feet', 'fall', 'excellence', 'especially', 'energ', 'emon', 'drawn', 'door', 'directed', 'dilled', 'didnt', 'crunchy', 'crispies', 'creme', 'cracked', 'cordon', 'construction', 'coniglio', 'coating', 'club', 'chilis', 'chi', 'certosina', 'cases', 'cant', 'canola', 'butterscotch', 'burnt', 'bundt', 'brought', 'british', 'brisket', 'braized', 'bouquet', 'boiler', 'began', 'backwoods', 'available', 'assure', 'asked', 'ask', 'approx', 'airtight', 'ah', '9inch', '85', '300', '2030', '1997', '1412', '121301', '121253', '110', '109', '05', 'youre', 'working', 'whol', 'whipping', 'weight', 'weeks', 'waste', 'volume', 'vietnamese', 'vermouth', 'understand', 'tuscan', 'tuck', 'tsps', 'truss', 'trial', 'treat', 'touched', 'tostada', 'toppings', 'told', 'toffee', 'thermidor', 'tartufi', 'tamari', 'tagliarelle', 'surely', 'supposed', 'sugo', 'success', 'subtle', 'stuck', 'striped', 'street', 'steven', 'stanleys', 'stacy', 'springs', 'spreading', 'spoonfuls', 'spent', 'speak', 'southern', 'sorry', 'smoothies', 'smith', 'skins', 'sitting', 'service', 'serrano', 'scrub', 'scrambled', 'scant', 'scallop', 'saw', 'sauteing', 'sal', 'rule', 'results', 'remarks', 'regard', 'reducedfat', 'received', 'reach', 'ravioli', 'ragout', 'quiche', 'question', 'prosciutto', 'pretzels', 'presence', 'praise', 'power', 'porkettes', 'pop', 'plan', 'pints', 'pineapplejuice', 'pigs', 'pies', 'piccante', 'pheasants', 'pearson', 'parmagiano', 'parchment', 'papri', 'pancakes', 'ovenproof', 'ovenbaked', 'oval', 'original', 'obtained', 'notion', 'nothing', 'none', 'ngredi', 'network', 'needs', 'navy', 'nacho', 'myself', 'money', 'moisture', 'mock', 'milks', 'mike', 'mg', 'methods', 'mess', 'measuring', 'mcmuffin', 'maui', 'marscapone', 'marchesas', 'mango', 'lumps', 'lombarda', 'loin', 'live', 'links', 'lingue', 'length', 'kumla', 'krumkake', 'knew', 'kernals', 'ken', 'keeps', 'jury', 'joan', 'jill', 'invert', 'ing', 'ie', 'ideas', 'ices', 'iceberg', 'hombourg', 'higher', 'herself', 'handled', 'haddock', 'gumbo', 'grappa', 'grapefruits', 'grains', 'gizzard', 'gives', 'gifts', 'genoese', 'garnished', 'gardenburger', 'frog', 'frittura', 'fries', 'fri', 'freezing', 'fontina', 'follows', 'folding', 'float', 'flavoured', 'fingertips', 'far', 'face', 'experiment', 'evening', 'es', 'elastic', 'dull', 'doneness', 'dolmas', 'different', 'diagonally', 'deveined', 'dessertspoonsful', 'decameron', 'david', 'cucumberavocado', 'crowd', 'crappie', 'corrals', 'corns', 'cooling', 'containers', 'complete', 'common', 'combi', 'closed', 'classic', 'circular', 'chilecheese', 'chickpeas', 'checked', 'character', 'change', 'chance', 'ch', 'centers', 'castroprauxel', 'casings', 'caribbean', 'carey', 'cappone', 'canadianstyle', 'calf', 'burger', 'bundle', 'bunches', 'buffet', 'buffalo', 'browns', 'brine', 'bottled', 'blades', 'blackened', 'bl', 'biga', 'beg', 'bed', 'beating', 'assemble', 'artist', 'arrosto', 'approximate', 'antipasti', 'agree', 'acorn', 'ace', 'accompaniment', '92', '89', '44543', '425°', '375', '3540', '212', '15ounce', '145', '115', '101', 'yours', 'wouldnt', 'wonderful', 'whiskey', 'wellgreased', 'wed', 'wd', 'warmed', 'walleye', 'visconti', 'vessel', 'vegetabl', 'varieties', 'usual', 'ust', 'twelve', 'turtle', 'tumeric', 'tue', 'triangles', 'trestrail', 'tough', 'total', 'timballo', 'ties', 'thought', 'thigh', 'theyre', 'thaw', 'thank', 'tenth', 'tbl', 'tails', 'sweetened', 'sushi', 'supper', 'sun', 'suet', 'sub', 'stroganoff', 'string', 'stream', 'strands', 'story', 'steel', 'steaming', 'spot', 'sponge', 'spite', 'soyoat', 'sorrentina', 'slush', 'slight', 'sinclairs', 'silver', 'shroom', 'sew', 'settle', 'serious', 'sent', 'sell', 'sedani', 'seasons', 'sear', 'schnell', 'scheme', 'says', 'sautez', 'sautee', 'sauted', 'salamander', 'runs', 'rose', 'rome', 'retain', 'resemble', 'removable', 'remains', 'regret', 'registers', 'reducedcalorie', 'recognised', 'reasons', 'rare', 'pupils', 'prune', 'protest', 'protein', 'proposition', 'product', 'prices', 'porcelletto', 'popped', 'pollastro', 'poem', 'please', 'plantains', 'pit', 'pistachios', 'pinto', 'pimentos', 'pico', 'pickled', 'piccioni', 'petto', 'person', 'permission', 'peeler', 'pe', 'passed', 'parmesean', 'paperlined', 'papaya', 'pandressed', 'packet', 'overlapping', 'origin', 'ordinary', 'opaque', 'omitted', 'ok', 'oily', 'oglethorpe', 'offset', 'nstead', 'northern', 'ngs', 'national', 'napkin', 'mousse', 'moosewood', 'month', 'montata', 'moistened', 'moisten', 'mixes', 'misto', 'mikes', 'mighty', 'metal', 'met', 'merluzzo', 'mediumsized', 'meatless', 'maybe', 'matter', 'matt', 'marie', 'marg', 'luncheon', 'luke', 'love', 'lost', 'lobsters', 'lite', 'lingua', 'limp', 'les', 'leg', 'learned', 'laurestinas', 'lattughe', 'latest', 'lastly', 'ladies', 'kraft', 'kosher', 'knefla', 'kielbasa', 'kernels', 'keeping', 'japanese', 'irish', 'interesting', 'interest', 'insides', 'ingredi', 'iced', 'httpwwwxsxmuedumjwrecipesvegetablesvegetarianmptofucollhtml', 'hots', 'hostess', 'host', 'himself', 'highquality', 'hey', 'hearty', 'hardboiled', 'halve', 'guinness', 'guacamole', 'grinder', 'grilling', 'griddle', 'gras', 'grandma', 'glazing', 'giving', 'genoa', 'generous', 'funghi', 'fritto', 'freezes', 'foie', 'florets', 'flip', 'flavored', 'flatten', 'flaked', 'fl', 'filetto', 'fifteen', 'fettucine', 'fell', 'felafel', 'favourite', 'fare', 'fagiano', 'ey', 'extravirgin', 'extralong', 'excel', 'everyone', 'escape', 'ensure', 'enhance', 'eels', 'edt', 'early', 'durable', 'dressings', 'doubt', 'discourse', 'directly', 'dine', 'curdle', 'cupful', 'culinary', 'cross', 'crock', 'crisco', 'correct', 'corradino', 'cornbread', 'content', 'containing', 'compote', 'cognac', 'coconutpecan', 'cocktail', 'coatings', 'coals', 'closely', 'ck', 'christmas', 'choucroute', 'chickpea', 'chickens', 'ced', 'ceased', 'carp', 'carl', 'career', 'carcass', 'candies', 'candied', 'butternut', 'burning', 'bue', 'broiling', 'brittle', 'bottoms', 'boi', 'blade', 'bitesized', 'beyond', 'batters', 'basi', 'balance', 'baguette', 'backbone', 'ateletti', 'ate', 'appetizer', 'amaretti', 'agrodolce', 'admirably', '8inch', '750', '450°', '325', '250', '228', '225', '222', '2171', '200°', '180', '150', '1312', '121406', '121325', '121254', '121247', '121209', '121126', '121053', '121051', '114', '103', '0', '„', '¥1', 'zuke', 'yes', 'yams', 'wtih', 'worth', 'wondering', 'women', 'woman', 'wise', 'wineglass', 'wife', 'wi', 'whom', 'whereupon', 'wherefore', 'whenever', 'welcome', 'wanted', 'walk', 'waldorf', 'wait', 'villereccia', 'vidalia', 'verze', 'version', 'vast', 'various', 'vander', 'upper', 'unless', 'unleavened', 'trypan', 'trying', 'tricia', 'treatment', 'transparent', 'traditional', 'trace', 'towards', 'toward', 'tossed', 'tof', 'tip', 'thinking', 'tests', 'testing', 'tested', 'temple', 'tator', 'tasty', 'tasting', 'tap', 'tail', 'szechwan', 'swordfish', 'sweeter', 'sully', 'sughillo', 'sufficient', 'suckers', 'successful', 'subject', 'stufato', 'strokes', 'stretch', 'stovetop', 'stored', 'stoned', 'stockpot', 'step', 'stanley—', 'stainless', 'spri', 'sport', 'spoons', 'spareribs', 'sorbet', 'somehow', 'somebody', 'snow', 'slash', 'simon', 'simmers', 'shiitake', 'shelled', 'shavings', 'seven', 'services', 'servants', 'sentence', 'sense', 'seam', 'se', 'scott', 'scotch', 'scatter', 'scallion', 'scaled', 'scalded', 'saying', 'savoiarda', 'sautepan', 'satisfied', 'sampl', 'salty', 'sale', 'sake', 'safe', 'rush', 'runny', 'rubbed', 'rounded', 'rosti', 'root', 'rocky', 'rock', 'ricer', 'restaurants', 'requires', 'replied', 'repast', 'remainder', 'remai', 'recommended', 'reading', 're', 'rate', 'rarely', 'range', 'radiccio', 'racks', 'qui', 'qt', 'pureed', 'provenzale', 'pretzel', 'preference', 'poured', 'poult', 'possess', 'portgarlic', 'pol', 'places', 'pizzas', 'pile', 'pierce', 'piemontese', 'phil', 'petti', 'petersen', 'pesce', 'pero', 'pellegrina', 'pears', 'past', 'parsely', 'panfish', 'pale', 'packaging', 'owing', 'ow', 'oves', 'overbake', 'ove', 'outer', 'ourselves', 'ordered', 'orangejuice', 'opinion', 'opening', 'oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo', 'oni', 'okra', 'offer', 'occassionally', 'ns', 'nos', 'norwegian', 'nonsti', 'nondairy', 'nicely', 'nd', 'nazionale', 'navarino', 'napolitana', 'napoletana', 'named', 'nachos', 'mystery', 'mussels', 'muscat', 'mountain', 'mornings', 'mocha', 'mmer', 'mirepoix', 'miracle', 'miniature', 'mince', 'millionaire', 'merely', 'memory', 'membranes', 'meaty', 'meatloaf', 'meatball', 'materials', 'maria', 'marble', 'mahimahi', 'luck', 'loves', 'lovely', 'looks', 'looked', 'listed', 'lined', 'lie', 'level', 'letting', 'letters', 'lets', 'lepre', 'lent', 'led', 'learnt', 'laura', 'latin', 'lathera', 'knowledge', 'knoepfla', 'kinda', 'kg', 'kelly', 'kay', 'kathy', 'kareema', 'kandell', 'jonathan', 'join', 'johns', 'jane', 'jackets', 'italiana', 'istufato', 'island', 'internal', 'insure', 'inspiration', 'insert', 'inexpensive', 'independent', 'incorporate', 'incomparable', 'included', 'imperatrice', 'imitation', 'hundred', 'httpwwwcscmuedumjwrecipesvegetablessdsredbeansricecollhtml', 'hr', 'houses', 'hotels', 'hotdish', 'hors', 'horizontally', 'hollow', 'hollandaise', 'hit', 'helped', 'haze', 'handiwork', 'halfway', 'hake', 'growing', 'grocery', 'greta', 'greatly', 'gravies', 'granny', 'gooey', 'gold', 'glance', 'girardet', 'generously', 'gathered', 'gastalda', 'garnie', 'garni', 'gallo', 'future', 'fungus', 'frothy', 'front', 'fritti', 'fricassee', 'freshwater', 'freshlyground', 'frank', 'forktender', 'forced', 'foam', 'flow', 'floating', 'fitted', 'fiori', 'finest', 'felt', 'favour', 'fan', 'familiar', 'falling', 'fajita', 'failed', 'facts', 'expert', 'expect', 'example', 'exactly', 'ery', 'englishman', 'eld', 'effect', 'ed', 'drizzling', 'drive', 'doussisconvexltcstulaneedu', 'distinguished', 'distilled', 'discovery', 'dipping', 'dino', 'dining', 'dilute', 'digestion', 'difficult', 'diehl', 'designed', 'desi', 'defrosted', 'deepfry', 'decided', 'death', 'darsieeceucdavisedu', 'damp', 'cutter', 'curly', 'curing', 'crystallized', 'crusty', 'crusts', 'crunch', 'crumbles', 'counter', 'costanza', 'corner', 'cookievalue', 'confectioners', 'condensed', 'compound', 'commercial', 'combinations', 'colonels', 'coco', 'cob', 'coarsley', 'claim', 'chopping', 'chief', 'chick', 'chefs', 'charred', 'changes', 'cetriuoli', 'caused', 'cause', 'castiron', 'carote', 'cardamon', 'caraway', 'capuccina', 'cap', 'canon', 'canavese', 'canapes', 'canadian', 'calls', 'calico', 'burritos', 'brussels', 'broiled', 'broccoflower', 'briami', 'breaking', 'breakfasts', 'brazil', 'bowtie', 'bottles', 'body', 'bodini', 'boat', 'blond', 'blackeyed', 'bisquick', 'biscuit', 'beverages', 'bengali', 'belief', 'becomes', 'basically', 'barry', 'bain', 'baccala', 'ay', 'avoid', 'average', 'australian', 'attached', 'atop', 'assorted', 'asparagi', 'artistic', 'arms', 'appropriate', 'appeared', 'announced', 'ankara', 'anise', 'andor', 'amy', 'ami', 'alternating', 'alternate', 'alone', 'aid', 'ai', 'agnello', 'act', 'achieve', 'absolutely', '450f', '425f', '425', '3tbsp', '3quart', '3inch', '2530', '23ds', '226', '220', '209', '200f', '187', '160f', '1518', '140', '134', '122', '1215', '121343', '121326', '121252', '121212', '121125', '121054', '121052', '120', '113', '0700', '000000000000000000000000000000000000000000000000000000000000000000000000', '—in', 'zuchinnis', 'zesty', 'z', 'yummy', 'yum', 'youve', 'youth', 'wrote', 'written', 'wraps', 'wrapped', 'worse', 'woods', 'wood', 'wonder', 'wisconsin', 'wing', 'wines', 'william', 'wholesome', 'whi', 'wellcoated', 'wedding', 'weather', 'waters', 'watched', 'wants', 'waiter', 'wafers', 'vote', 'viewing', 'view', 'victim', 'verdure', 'ventral', 'venetian', 'veggoes', 'vegan', 'vastly', 'vari', 'usenet', 'useless', 'useful', 'usage', 'upright', 'unpopped', 'unpalatable', 'unfamiliar', 'unappetising', 'turnovers', 'tubular', 'tub', 'truth', 'triumphs', 'triumph', 'trench', 'tragedy', 'torti', 'tomorrow', 'toadstools', 'toa', 'tines', 'tin', 'tight', 'thomas', 'thickly', 'thi', 'themes', 'thefollowing', 'texas', 'term', 'tentacles', 'tends', 'temp', 'tells', 'teaspoonfuls', 'teacup', 'teaching', 'taught', 'tartara', 'targone', 'tapenade', 'tang', 'tamis', 'talking', 'taffy', 'system', 'swell', 'sweets', 'suppose', 'super', 'sunday', 'sullys', 'suitable', 'suit', 'sugarcinnamon', 'sue', 'successfully', 'subside', 'styles', 'sturdy', 'study', 'stronger', 'strength', 'strawberryrhubarb', 'strange', 'straining', 'strainer', 'straightsided', 'stout', 'stores', 'stopped', 'stitch', 'stewpans', 'steps', 'steamer', 'steady', 'started', 'standing', 'stal', 'squirt', 'sprinkling', 'sprinklewith', 'sprays', 'splitting', 'specials', 'spears', 'speaking', 'spagnuola', 'sp', 'south', 'soured', 'solidifies', 'solid', 'soggy', 'softer', 'social', 'snipped', 'snip', 'snickerdoodles', 'snaps', 'snacks', 'smart', 'slivers', 'slits', 'slit', 'slip', 'slide', 'skewer', 'sister', 'simplicity', 'silken', 'silence', 'shucked', 'shrooms', 'shellshaped', 'shark', 'shanes', 'servi', 'serrated', 'semisweet', 'selvatica', 'selected', 'select', 'seldom', 'seasoni', 'search', 'scraps', 'scraped', 'scotched', 'scooped', 'schools', 'scandinavian', 'scallope', 'scald', 'savoiardi', 'saucy', 'sarda', 'sapor', 'sandbakelser', 'saltpepper', 'salamoia', 'rushed', 'roughly', 'rosette', 'roots', 'romans', 'role', 'roets', 'road', 'rm', 'ritz', 'risen', 'ripieni', 'ribbons', 'ri', 'result', 'repeatedly', 'remoulade', 'relief', 'rejoice', 'reheated', 'reggiano', 'refrigerating', 'reddish', 'recent', 'recall', 'rec', 'realise', 'realemon', 'reaches', 'razor', 'rappresa', 'raisans', 'ragg', 'races', 'rabbits', 'quinoa', 'pumpernickel', 'pulse', 'prove', 'proposed', 'propose', 'proportions', 'professionally', 'production', 'procedure', 'pro', 'prior', 'prince', 'primaverile', 'pressing', 'presentation', 'precooked', 'poupon', 'potsum', 'postpone', 'possibly', 'portabella', 'porridge', 'popper', 'ponds', 'pollack', 'poke', 'poisonous', 'poetry', 'pocketbook', 'plums', 'plainly', 'pith', 'pitas', 'pistachio', 'pistacchi', 'piping', 'pinocchi', 'pierced', 'piecrust', 'pharon', 'persons', 'perniciotti', 'peri', 'perciatelli', 'pepperoncini', 'peek', 'pear', 'patch', 'pastrylined', 'pastes', 'parting', 'parsleypecan', 'parsl', 'parmegiana', 'papers', 'panch', 'pamsprayed', 'pam', 'paid', 'overworking', 'overtop', 'overmix', 'orleans', 'ordering', 'optimal', 'opportunity', 'onionchopped', 'onethird', 'oilsprayed', 'office', 'odour', 'odd', 'nutty', 'nutritious', 'nstant', 'nol', 'nkle', 'nizzarda', 'news', 'nectar', 'nature', 'nation', 'naselli', 'nancy', 'names', 'muse', 'muellerrecipe', 'movement', 'move', 'mound', 'motion', 'morewater', 'mood', 'montone', 'monotony', 'monds', 'modern', 'modanese', 'miste', 'mini', 'miller', 'michael', 'merits', 'mention', 'melon', 'medieval', 'medallions', 'measures', 'meals', 'master', 'martin', 'marked', 'mark', 'marinati', 'manufacturers', 'mandorle', 'makea', 'majority', 'maize', 'maigre', 'maid', 'madame', 'mad4ellisuchicagoedu', 'mac', 'lowsalt', 'loud', 'loss', 'loses', 'lorraine', 'loose', 'looking', 'log', 'local', 'lobes', 'listened', 'list', 'liebig', 'lemoncoriander', 'lemoncolored', 'leftovers', 'leftover', 'lead', 'le', 'laughing', 'lately', 'largely', 'larder', 'land', 'laid', 'ks', 'krispies', 'kringla', 'kransa', 'knows', 'knephlas', 'knephla', 'kneading', 'kids', 'key', 'kenneth', 'julienne', 'jubilee', 'jahr', 'jacobson—', 'italianstyle', 'italians', 'istufa', 'issue', 'ira', 'intestines', 'intervals', 'intelligent', 'institutions', 'innocent', 'inn', 'informed', 'inferior', 'indexed', 'inclined', 'improvement', 'improve', 'importent', 'ike', 'ik', 'ig', 'husband', 'hungry', 'humours', 'human', 'httpwwwxsxmuedumjwrecipesvegetableszuchinnizuchinnicollhtml', 'httpwwwxsxmuedumjwrecipesvegetablesvegetarianveglasagnechilicollhtml', 'httpwwwxsxmuedumjwrecipesvegetablesmushroomsrnushcollhtml', 'hrs', 'honourable', 'holes', 'highest', 'hiding', 'heres', 'heavenly', 'heating', 'havent', 'harvest', 'hartland', 'happy', 'happen', 'handwriting', 'handling', 'halving', 'halfinch', 'halfhour', 'halfanhour', 'guy', 'grounds', 'gross', 'grief', 'grey', 'gretchen', 'greater', 'greasy', 'gray', 'grater', 'grapenuts', 'grant', 'grandmas', 'grand', 'grams', 'graced', 'gout', 'goat', 'genuine', 'gentle', 'genius', 'gather', 'gas', 'gallon', 'further', 'function', 'fryingpan', 'fryer', 'froth', 'frostings', 'fritta', 'friday', 'france', 'fragole', 'fragments', 'fortunate', 'forth', 'forno', 'formula', 'force', 'fond', 'foamed', 'fly', 'flowers', 'flower', 'flatleafed', 'fisherman', 'fiodi', 'fins', 'finds', 'finding', 'final', 'filled', 'fili', 'figs', 'fiber', 'feed', 'fasten', 'fashioned', 'fano', 'fair', 'extraneous', 'explanation', 'evidently', 'evidence', 'evaporates', 'est', 'espresso', 'erbe', 'equivalent', 'equals', 'equally', 'entree', 'enter', 'englishmen', 'emu', 'empty', 'elegant', 'el', 'edna', 'edible', 'eces', 'eave', 'east', 'dribble', 'dream', 'drawingroom', 'draw', 'draining', 'dorado', 'donut', 'dolce', 'doeuvre', 'ditalini', 'distinction', 'dipped', 'dindo', 'dimple', 'dilly', 'dijonstyle', 'difference', 'die', 'deviled', 'developed', 'des', 'depth', 'deglaze', 'decorative', 'declare', 'dealer', 'dat', 'dariole', 'daresay', 'danish', 'dampen', 'dairy', 'dagnello', 'dad', 'currant', 'curiosity', 'cupcakes', 'cuisine', 'crotopo', 'croccante', 'crispness', 'crispier', 'crimini', 'cried', 'creole', 'cremona', 'creams', 'crawdad', 'crack', 'courgettes', 'courgette', 'counsels', 'costly', 'coscia', 'copper', 'cookiesheet', 'cooki', 'cookbook', 'conversation', 'controlling', 'continually', 'contains', 'consummate', 'consuming', 'considering', 'consideration', 'condiment', 'concentrated', 'composition', 'commonplace', 'comb', 'com', 'colours', 'coconutalmond', 'cobbler', 'coarsegrain', 'clearing', 'cleanly', 'clarified', 'city', 'ci', 'chosen', 'cholesterol', 'chokes', 'chillies', 'chilli', 'chilean', 'chevre', 'chase', 'charm', 'charge', 'characteristics', 'changing', 'censure', 'cash', 'carton', 'carrotpineapple', 'carolina', 'carol', 'carmelitas', 'caramelized', 'capucina', 'cannellini', 'cal', 'buying', 'butter4', 'burro', 'burner', 'bull', 'bulk', 'brownings', 'broad', 'brings', 'bright', 'brick', 'breath', 'breadcrumb', 'brandied', 'boxes', 'books', 'bodino', 'blunt', 'blackberries', 'bigos', 'bibb', 'beth', 'believed', 'belgium', 'bedroom', 'beatenup', 'basket', 'bakers', 'bad', 'awful', 'avacado', 'author', 'authentic', 'ati', 'atelets', 'at225°for', 'astachi', 'assured', 'assembling', 'aspic', 'asking', 'asiago', 'arugula', 'artificial', 'arborio', 'approval', 'applejuice', 'annie', 'anitra', 'animal', 'anguilla', 'anglers', 'amongst', 'among', 'america', 'alrge', 'allude', 'allowing', 'alle', 'alive', 'alarm', 'akes', 'african', 'afraid', 'advanced', 'ads', 'admit', 'adj', 'adhere', 'addresses', 'addressed', 'acid', 'achovies', 'achievement', 'accompany', 'accept', 'absolute', 'abroad', '9x9', '94', '900', '8oz', '812', '800', '6quart', '50g2oz', '4560', '4045', '300f', '2cup', '2999999999999999999999999999999999999999999999999999999999999999999999999', '28ounce', '275', '230', '229', '216', '214', '204', '201', '189', '183', '180c', '165', '163', '160', '142', '127', '121324', '121300', '121240', '121217', '119', '118', '117', '104', '102', '0400', '01', '■kkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk', 'zuchini', 'zucchiniomlett', 'zucchine', 'zucchina', 'zucchi', 'zimino', 'zampetti', 'yuba', 'younger', 'yolkfree', 'yohurt', 'yi', 'yashodhara', 'wretched', 'worry', 'wornout', 'worms', 'worldwide', 'workman', 'worked', 'worcester', 'won', 'womans', 'witnessed', 'witll', 'wishes', 'wisely', 'wings', 'win', 'wilts', 'wigmore', 'widely', 'whose', 'whitebait', 'whispered', 'whisper', 'wherewith', 'whateverto', 'west', 'welltrimmed', 'wellreduced', 'wellbuttered', 'wellbeaten', 'weighty', 'weights', 'weigh', 'wedging', 'wearing', 'wealth', 'wdl', 'ways', 'waved', 'wasson', 'warning', 'war', 'wandered', 'wallace', 'waffleiron', 'vouch', 'volkmann', 'vital', 'vinegarette', 'ville', 'village', 'victory', 'victimes', 'vickie', 'vi3', 'vexation', 'vers', 'vermicelli', 'venture', 'venkataraman', 'venerable', 'vein', 'vegetableoil', 'veg', 'vanished', 'value', 'valuable', 'valley', 'utterance', 'utter', 'utes', 'uses', 'upwards', 'unwonted', 'untill', 'unsurpassed', 'unpleasantly', 'unmold', 'unlike', 'universal', 'units', 'unit', 'unflavored', 'underneath', 'underdone', 'unbeaten', 'unbaked', 'unattractive', 'unable', 'um', 'ul', 'types', 'ty', 'twothirds', 'twist', 'twentyfour', 'tv', 'turkish', 'ture', 'turbinado', 'tuesday', 'tsatsiki', 'trusty', 'tropical', 'trophies', 'triste', 'triglie', 'triestina', 'treasure', 'travelled', 'translating', 'translates', 'translated', 'transferring', 'traditions', 'townsfolk', 'toweling', 'tournesols', 'tourlou', 'tougher', 'touching', 'touches', 'tots', 'tot', 'torts', 'tortino', 'tonys', 'tongs', 'tone', 'tomatores', 'tomatoe', 'tolosa', 'tolentina', 'toasty', 'toasts', 'tissue', 'tions', 'timbales', 'ti', 'thursday', 'thumb', 'throwing', 'threw', 'thinks', 'thicknesses', 'thickest', 'thewater', 'theres', 'th', 'tes', 'terracina', 'terms', 'tendency', 'temperatures', 'temper', 'tegame', 'tedious', 'teaspoonsful', 'tears', 'tearing', 'team', 'te', 'tbsps', 'tautog', 'tara', 'taper', 'tamale', 'tahi', 'tacchinotto', 'tables', 'szechuan', 'sympathy', 'symmetrically', 'syllabub', 'swivelbladed', 'swirling', 'suspected', 'surroundings', 'surrounded', 'suprema', 'supposing', 'superb', 'sunf', 'sunburgers', 'sultanas', 'suicide', 'suggests', 'suggested', 'sudden', 'succeeded', 'succeed', 'substitutions', 'substituted', 'substance', 'sublimination', 'subjected', 'sturgeon', 'stucture', 'struggle', 'struck', 'strong', 'stringy', 'strings', 'strike', 'strenuous', 'streams', 'straw', 'strained', 'storage', 'stood', 'stomach', 'stocked', 'stiring', 'stimulating', 'stiffer', 'stemmed', 'steep', 'stayed', 'state', 'starkey', 'stanzas', 'stan', 'stack', 'srivastav', 'sridhar', 'squeezed', 'sprout', 'springform', 'spots', 'spooned', 'spongecake', 'spoken', 'spoilt', 'spiral', 'spinache', 'spinacci', 'spill', 'spicing', 'specific', 'spearing', 'spatters', 'sparingly', 'sparing', 'spare', 'southwestern', 'soupy', 'sounds', 'soul', 'song', 'solve', 'soles', 'soffiato', 'socalled', 'snapper', 'smoking', 'smashed', 'smash', 'smallest', 'smal', 'sm', 'slurry', 'slowcooker', 'slicer', 'skip', 'skill', 'sixth', 'sits', 'sitfor', 'siphon', 'sinclai', 'signs', 'sifting', 'sierve', 'shrimpstuffed', 'shows', 'shower', 'shorts', 'shoiinaga', 'shepards', 'sheep', 'shed', 'shears', 'shared', 'sh', 'sfegusubvmccbuffaloedu', 'seventh', 'settled', 'setcookie', 'serv', 'seperate', 'sending', 'send', 'selfrising', 'seated', 'scup', 'score', 'scorch', 'scissors', 'science', 'scholes', 'scented', 'scarcely', 'scalopini', 'scales', 'savour', 'sauvignon', 'saucemarinade', 'sauceboat', 'satisfy', 'sardines', 'sara', 'santa', 'sanseverino', 'sanjeev', 'san', 'saltto', 'salamimac', 'saint', 'safflower', 'safari', 'sacrifice', 'russian', 'russia', 'rumminger', 'rules', 'rubber', 'rst', 'route', 'rough', 'rotini', 'rotating', 'roprauxel', 'ropes', 'rol', 'rods', 'rodney', 'robust', 'robin', 'roasts', 'roaster', 'rl', 'rive', 'ripieno', 'ripiene', 'rigid', 'richer', 'ricein', 'ricecashew', 'rib', 'rewarm', 'reverence', 'retried', 'retreat', 'retail', 'responsible', 'respectable', 'resembles', 'resealable', 'requisitioned', 'request', 'reproduce', 'replaced', 'repeated', 'rendering', 'render', 'renaissance', 'reminded', 'remind', 'remarked', 'reliable', 'release', 'reine', 'regularly', 'regretted', 'regina', 'refrigeration', 'refer', 'reducing', 'reducedsodium', 'rectangle', 'recorded', 'reckon', 'recently', 'recalled', 'reads', 'rd', 'ratatouille', 'rat', 'rapidly', 'ranger', 'ran', 'raisi', 'raised', 'ragu', 'radicchio', 'racine', 'questions', 'quest', 'queens', 'qualities', 'q', 'putting', 'pursuit', 'purple', 'pure', 'purchase', 'pulpy', 'pulled', 'published', 'publication', 'prunejuice', 'provided', 'provide', 'proud', 'prosciuttosalmon', 'proper', 'prologue', 'project', 'progressive', 'profound', 'profitably', 'produced', 'proclaiming', 'problem', 'private', 'printed', 'princess', 'prete', 'preserves', 'preserve', 'prebaked', 'practice', 'pple', 'ppermint', 'powers', 'pounding', 'poulet', 'pottkuchen', 'pottage', 'potcake', 'potaties', 'posting', 'posted', 'possibilities', 'position', 'pose', 'portuguese', 'portobella', 'porgy', 'porcupine', 'pool', 'pompadour', 'poll', 'polish', 'points', 'poet', 'pods', 'poblano', 'poaching', 'plunge', 'plentiful', 'pleasers', 'plead', 'plague', 'placing', 'pistacchios', 'piselli', 'pipe', 'pintos', 'pilaf', 'pieshdl', 'pictures', 'picture', 'picnic', 'picks', 'picked', 'pick', 'piccata', 'picante', 'pia', 'phrase', 'philosopher', 'peterson', 'pesci', 'pes', 'perugia', 'perigo', 'perfection', 'peppy', 'peppersif', 'peppermints', 'penetrate', 'peeling', 'peculiar', 'peasants', 'peace', 'paying', 'pawar', 'paused', 'paul', 'patted', 'pasticci', 'partly', 'particles', 'parmigian', 'parm', 'parisian', 'parigina', 'parfait', 'parents', 'pared', 'pare', 'parboil', 'papiliotte', 'paperthin', 'papas', 'panna', 'panfry', 'panforte', 'palatable', 'pair', 'pages', 'packing', 'owfat', 'ower', 'overrun', 'overcooked', 'ov', 'outrage', 'outdoor', 'outcome', 'outbreak', 'ours', 'ottawa', 'oth', 'ot', 'originated', 'originally', 'organ', 'orangecranberry', 'onionsin', 'onionmint', 'onger', 'onehalf', 'omitonion', 'omelettes', 'omelet', 'om', 'oldest', 'oilvinegar', 'oils', 'ogg', 'oe', 'october', 'obvously', 'obtain', 'observe', 'obliged', 'nuked', 'nuke', 'nowhere', 'november', 'nov', 'nougat', 'notice', 'noted', 'north', 'nonlowfat', 'noknead', 'nobody', 'ninth', 'nine', 'nika', 'newspaper', 'nevertheless', 'net', 'nervous', 'ner', 'neophytes', 'neither', 'negligent', 'neglect', 'necessarily', 'neatly', 'neapplejuice', 'neappl', 'navel', 'naturally', 'narad', 'mustnt', 'mustardlike', 'mushroombacon', 'musca', 'murdering', 'multigrain', 'mukesh', 'mueller—', 'mt', 'mozzerella', 'moussaka', 'mothers', 'mortons', 'moral', 'months', 'montano', 'monster', 'mond', 'moments', 'momentary', 'moi', 'moderatelyhigh', 'mizidra', 'mixmix', 'mist', 'mirza', 'miracles', 'mints', 'minnies', 'minnie', 'minister', 'million', 'milled', 'milky', 'milan', 'mignon', 'middleclass', 'microwaveable', 'microsafe', 'meuniere', 'metric', 'messrs', 'merit', 'merest', 'mercifully', 'menus', 'mental', 'meno', 'men', 'melba', 'mein', 'megere', 'medi', 'meatloaves', 'measurement', 'meant', 'mcdermott', 'mccorkendale', 'mayonaise', 'maxim', 'masterpieces', 'masterpiece', 'masses', 'mashedup', 'mas', 'martys', 'marshmellows', 'marry', 'married', 'markets', 'marinato', 'marinata', 'marinara', 'margerine', 'marcianetcomcom', 'marcia', 'marc', 'maplewalnut', 'manufactured', 'manque', 'manners', 'manifest', 'managed', 'malmsey', 'majoram', 'major', 'mahshee', 'maggie', 'madhur', 'maccheroni', 'macaroons', 'macaroon', 'lying', 'lutefisk', 'luscious', 'luncher', 'luncheons', 'lump', 'lowsodium', 'louisiana', 'lorenese', 'looz', 'lookalike', 'longpronged', 'lombardy', 'lived', 'littleneck', 'litle', 'lira', 'liqueur', 'lionese', 'linguini', 'lindabdt', 'likes', 'liked', 'lift', 'lies', 'libertylibertycom', 'liberally', 'lettuces', 'letter', 'lesson', 'leslie', 'lenta', 'lengths', 'lend', 'lemony', 'lemonade', 'leitner', 'leek', 'learning', 'lctofu', 'lazenbys', 'layering', 'lax', 'latte', 'latitude', 'lardellate', 'lack', 'kumar', 'koftas', 'knockwurst', 'king', 'kindly', 'kidneys', 'kick', 'kibbeh', 'kerala', 'keen', 'katz', 'kathie', 'karla', 'kabobs', 'justice', 'juniper', 'june', 'jumbo', 'julia', 'juicy', 'judicious', 'journals', 'journal', 'jongleuraolcom', 'jo', 'jerky', 'jellyroll', 'january', 'janis', 'jagordonagsmuclaedu', 'jaffreys', 'ivi', 'item', 'isinglass', 'ish', 'isbn', 'irresistible', 'iquefier', 'ions', 'invite', 'inverted', 'interval', 'interior', 'instruction', 'instance', 'inspect', 'inserted', 'inns', 'ingratitude', 'infarcite', 'inevitable', 'industry', 'indoor', 'individually', 'individuality', 'indicate', 'india', 'indentation', 'increased', 'incongruity', 'improves', 'impression', 'imperfections', 'imminent', 'imboracciate', 'imam', 'imagine', 'imagination', 'ima', 'ilbulgur', 'il', 'iceburg', 'ian', 'huncaina', 'hummus', 'humble', 'hull', 'hugs', 'httpwwwxsxmuedumjwrecipesvegetablesvegetarianveggieburgernutshtml', 'httpwwwxsxmuedumjwrecipesvegetablesvegetarianvegchilicollhtml', 'httpwwwxsxmuedumjwrecipesvegetablespotatomarjorampotcasshtml', 'httpwwwcscmuedumjwrecipesvegetableszuchinnizuchinnicollhtml', 'httpwwwcscmuedumjwrecipesvegetableszuchinniedzuccollhtml', 'httpwwwcscmuedumjwrecipesvegetablesvegetarianblkbeanbroccolihtml', 'httpwwwcscmuedumjwrecipesvegetablesredkalecoconuthtrnl', 'httpwwwcscmuedumjwrecipesvegetableschoucroutegarniehtml', 'howls', 'howeve', 'hovering', 'housekeeping', 'hotel', 'horses', 'hormel', 'horizontal', 'hooks', 'honour', 'honeyed', 'honest', 'hole', 'hocks', 'highish', 'hidden', 'hickory', 'henry', 'hen', 'helping', 'held', 'height', 'hear', 'healthy', 'hazeltons', 'hayes', 'haunted', 'hat', 'haricot', 'hardly', 'harden', 'hardbake', 'harbor', 'happened', 'hankers', 'hankering', 'handsome', 'hamdan', 'halligan', 'hail', 'hacienda', 'habit', 'habanero', 'guilty', 'guess', 'gubbio', 'group', 'groundnut', 'groats', 'grmandrew', 'gridiron', 'greeks', 'greece', 'greasing', 'granules', 'grai', 'gr', 'goodsized', 'goats', 'gnoechi', 'gnocchis', 'glossy', 'girls', 'gingerroot', 'gin', 'giblets', 'ghtl', 'ght', 'ghost', 'gherkin', 'ghassemi', 'ghanoush', 'gesture', 'general', 'gelatine', 'gazpacho', 'garnishing', 'garland', 'gardenstuffed', 'galantina', 'gala', 'gain', 'fussili', 'fusilli', 'frys', 'fruited', 'frosted', 'fritters', 'fritata', 'friendly', 'fricassea', 'frenchman', 'freles', 'freely', 'franks', 'francesca', 'fraiche', 'fr', 'fourth', 'foundation', 'forward', 'fortnight', 'forte', 'formulas', 'forming', 'formal', 'forks']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data for autoregression"
      ],
      "metadata": {
        "id": "_8D48FoPIpSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compromise on sequence length to have same-size batches\n",
        "sequence_length = 32 # GPT uses 2200...\n",
        "\n",
        "def create_dataset_for_autoregression(dataset):\n",
        "    x_inputs = []\n",
        "    y_outputs = []\n",
        "    for samples in dataset: # Get a batch, should be all the books\n",
        "        samples = encoder(samples).numpy()\n",
        "        for sample in tqdm(samples): # Go through each of the books\n",
        "\n",
        "            # Pad at the beggining of each book\n",
        "            padding_token_id = vocabulary.index(\"\")\n",
        "            padding = [padding_token_id] * sequence_length\n",
        "            sample = padding + list(sample)\n",
        "\n",
        "            # Map to input output pairs\n",
        "            for start_index in range(0, len(sample) - sequence_length):\n",
        "                x = sample[start_index:start_index + sequence_length]\n",
        "                y = sample[start_index + sequence_length]\n",
        "                x_inputs += [x] # append\n",
        "                y_outputs += [y]\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices((x_inputs, y_outputs))\n",
        "\n",
        "\n",
        "dataset_train = create_dataset_for_autoregression(dataset_original_train)\n",
        "dataset_valid = create_dataset_for_autoregression(dataset_original_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scaSDXATINEH",
        "outputId": "4e87b4a7-3c68-4acf-f413-3309df0dcd43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:01<00:00,  7.58it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 38.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualise how autoregression works\n",
        "\n",
        "def decode(indices):\n",
        "    return \" \".join([vocabulary[index] for index in indices if vocabulary[index] is not \"\"])\n",
        "\n",
        "for input, output  in dataset_train.take(10):\n",
        "    print(\"input: \", \" \".join([str(x) for x in input.numpy()]))\n",
        "    print(\"output:\", output.numpy())\n",
        "    print(\"input decoded: \", decode(input))\n",
        "    print(\"output decoded:\", decode([output]))\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKznecQFMnpG",
        "outputId": "00bfb80f-430b-4ddb-828c-8b9e02369f6f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "output: 86\n",
            "input decoded:  \n",
            "output decoded: cooking\n",
            "\n",
            "input:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 86\n",
            "output: 336\n",
            "input decoded:  cooking\n",
            "output decoded: 200\n",
            "\n",
            "input:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 86 336\n",
            "output: 105\n",
            "input decoded:  cooking 200\n",
            "output decoded: recipes\n",
            "\n",
            "input:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 86 336 105\n",
            "output: 13\n",
            "input decoded:  cooking 200 recipes\n",
            "output decoded: for\n",
            "\n",
            "input:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 86 336 105 13\n",
            "output: 143\n",
            "input decoded:  cooking 200 recipes for\n",
            "output decoded: italian\n",
            "\n",
            "input:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 86 336 105 13 143\n",
            "output: 232\n",
            "input decoded:  cooking 200 recipes for italian\n",
            "output decoded: dishes\n",
            "\n",
            "input:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 86 336 105 13 143 232\n",
            "output: 338\n",
            "input decoded:  cooking 200 recipes for italian dishes\n",
            "output decoded: share\n",
            "\n",
            "input:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 86 336 105 13 143 232 338\n",
            "output: 359\n",
            "input decoded:  cooking 200 recipes for italian dishes share\n",
            "output decoded: metxt\n",
            "\n",
            "input:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 86 336 105 13 143 232 338 359\n",
            "output: 3\n",
            "input decoded:  cooking 200 recipes for italian dishes share metxt\n",
            "output decoded: the\n",
            "\n",
            "input:  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 86 336 105 13 143 232 338 359 3\n",
            "output: 693\n",
            "input decoded:  cooking 200 recipes for italian dishes share metxt the\n",
            "output decoded: cooks\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def render_history(history):\n",
        "    plt.title(\"Training loss vs. validation loss\")\n",
        "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    plt.title(\"Training accuracy vs. validation accuracy\")\n",
        "    plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "    plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "S9VgZ5vFVLwY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "lH3E2gJOWyKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers\n",
        "\n",
        "embedding_size = 128\n",
        "\n",
        "model = models.Sequential()\n",
        "# no need of encoding layer, as data already encoded\n",
        "model.add(layers.Embedding(vocabulary_size, embedding_size, input_length=sequence_length)) \n",
        "model.add(layers.Dropout(0.3)) # dropout activations\n",
        "#model.add(layers.LSTM(512, return_sequences=True))\n",
        "model.add(layers.LSTM(512))\n",
        "model.add(layers.Dropout(0.4))\n",
        "#model.add(layers.LSTM(1024))\n",
        "#model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(vocabulary_size, activation=\"softmax\")) # 10.000 words, word with highest activation will be the predicted\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\", # avoids having to implement one-hot encoder\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# train\n",
        "history = model.fit(\n",
        "    dataset_train.shuffle(5000).batch(512),\n",
        "    epochs=3,\n",
        "    validation_data=dataset_valid.batch(512)\n",
        ")\n",
        "\n",
        "render_history(history)"
      ],
      "metadata": {
        "id": "Y6LaIN2mWwaV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "outputId": "ff89a0f2-877c-486c-d43f-2011ae66f008"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 32, 128)           640000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 128)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 512)               1312768   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5000)              2565000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,517,768\n",
            "Trainable params: 4,517,768\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "  10/1004 [..............................] - ETA: 48:06 - loss: 7.9130 - accuracy: 0.0906"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ecce23049b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation"
      ],
      "metadata": {
        "id": "e4Jlu3eKa32y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate(model, seed_text, generated_sequence_length, temperature):\n",
        "\n",
        "    input_sequence = encoder(seed_text).numpy()\n",
        "\n",
        "    generated_sequence = list(input_sequence[::])\n",
        "\n",
        "    # Pad.\n",
        "    padding = [0] * (sequence_length - len(input_sequence))\n",
        "    input_sequence = padding + list(input_sequence)\n",
        "\n",
        "    # Generate the sequence by repeatedly predicting.\n",
        "    while len(generated_sequence) < generated_sequence_length:\n",
        "        prediction = model.predict(np.expand_dims(input_sequence, axis=0))\n",
        "        predicted_index = get_index_from_prediction(prediction[0], temperature)\n",
        "        generated_sequence.append(predicted_index)\n",
        "        input_sequence = input_sequence[1:]\n",
        "        input_sequence.append(predicted_index)\n",
        "\n",
        "    # Convert the generated sequence to a string.\n",
        "    text = decode(generated_sequence)\n",
        "    print(text)\n",
        "    print(\"\")\n",
        "\n",
        "        \n",
        "def get_index_from_prediction(prediction, temperature=0.0):\n",
        "    \"\"\" Gets an index from a prediction. \"\"\"\n",
        "\n",
        "    # Zero temperature - use the argmax.\n",
        "    if temperature == 0.0:\n",
        "        return np.argmax(prediction)\n",
        "\n",
        "    # Non-zero temperature - do some random magic.\n",
        "    else:\n",
        "        prediction = np.asarray(prediction).astype('float64')\n",
        "        prediction = np.log(prediction) / temperature\n",
        "        exp_prediction= np.exp(prediction)\n",
        "        prediction = exp_prediction / np.sum(exp_prediction)\n",
        "        probabilities = np.random.multinomial(1, prediction, 1)\n",
        "        return np.argmax(probabilities)\n",
        "  \n",
        "\n",
        "generate(model, \"garlic onion\", 100, temperature=1.0)"
      ],
      "metadata": {
        "id": "0uOR_OL-a7di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JeXQv2aHa9P7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}